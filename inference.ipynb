{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbbarclay/mine/blob/master/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyK5mM1Q23wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "3efd6f43-36e1-4b22-8643-36305565610a"
      },
      "source": [
        "!pip show tensorflow\n",
        "!pip show tensorboard\n",
        "!pip show python\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: absl-py, protobuf, tensorboard, numpy, gast, keras-preprocessing, astor, wheel, six, grpcio, keras-applications, termcolor, tensorflow-estimator\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n",
            "Name: tensorboard\n",
            "Version: 1.13.1\n",
            "Summary: TensorBoard lets you watch Tensors Flow\n",
            "Home-page: https://github.com/tensorflow/tensorboard\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: wheel, werkzeug, absl-py, six, markdown, grpcio, numpy, protobuf\n",
            "Required-by: tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGtmfqI53eID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8f4aef41-014a-41af-f282-2a6891ec97ae"
      },
      "source": [
        "%cd\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive six"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-pil is already the newest version (5.1.0-1).\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-lxml is already the newest version (4.2.1-1ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "\u001b[K     |████████████████████████████████| 993kB 9.7MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8N2Xql3oGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59fe6315-8ae3-4e4d-8cb1-e62e3c1a01ee"
      },
      "source": [
        "# Compile protocol buffers\n",
        "%cd ~/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj456Pfw4Xvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure env variables\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G45j6Kxi3zBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bb01c57-2005-4727-b3a6-d1ddc3c8adbe"
      },
      "source": [
        "%cd ~/models/research/\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "sys.path.append(\"/models/research/\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuj5_ps28o4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d845a15e-9c84-43f9-cadc-5c95ade02460"
      },
      "source": [
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        " \n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        " \n",
        "PATH_TO_LABELS = os.path.join('/root/models/research/object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "print(PATH_TO_LABELS)\n",
        " \n",
        "NUM_CLASSES = 90"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research/object_detection/data/mscoco_label_map.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-wr06Zv9dkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "209adef9-e5c9-43d6-ef7d-b27658f77625"
      },
      "source": [
        "%cd /root/models/research/object_detection/data\n",
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research/object_detection/data\n",
            "ava_label_map_v2.1.pbtxt\n",
            "face_label_map.pbtxt\n",
            "fgvc_2854_classes_label_map.pbtxt\n",
            "kitti_label_map.pbtxt\n",
            "mscoco_complete_label_map.pbtxt\n",
            "mscoco_label_map.pbtxt\n",
            "mscoco_minival_ids.txt\n",
            "oid_bbox_trainable_label_map.pbtxt\n",
            "oid_object_detection_challenge_500_label_map.pbtxt\n",
            "oid_v4_label_map.pbtxt\n",
            "pascal_label_map.pbtxt\n",
            "pet_label_map.pbtxt\n",
            "\u001b[0m\u001b[01;34mssd_mobilenet_v1_coco_2017_11_17\u001b[0m/\n",
            "ssd_mobilenet_v1_coco_2017_11_17.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvSIt1eL85SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "241cbb27-76a1-448b-fc86-c6ce27b2d8af"
      },
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        " \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "print(PATH_TO_CKPT)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZtYQYfw9AiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "print(label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9xPn4B-ErC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d67b4622-994b-42a8-bed6-c481a22ef10a"
      },
      "source": [
        "%mkdir ~/data\n",
        "%cd ~/data\n",
        "\n",
        "!git clone https://github.com/aaronbbarclay/mine\n",
        "%cd mine/machineLearning/macbethIdentify/data/\n",
        "%ls\n",
        "!unzip macbeth_identify.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/data’: File exists\n",
            "/root/data\n",
            "fatal: destination path 'mine' already exists and is not an empty directory.\n",
            "/root/data/mine/machineLearning/macbethIdentify/data\n",
            "\u001b[0m\u001b[01;34mmacbeth_identify\u001b[0m/  \u001b[01;32mmacbeth_identify.zip\u001b[0m*  \u001b[01;34m__MACOSX\u001b[0m/\n",
            "Archive:  macbeth_identify.zip\n",
            "replace macbeth_identify/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em1JpqhC-_UN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2daaf1ec-8ea0-4d15-b16e-5548b2114554"
      },
      "source": [
        "%cd ~/data/mine\n",
        "\n",
        "imageFilesBasePath = PATH_TO_TEST_IMAGES_DIR = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/img'\n",
        "annotationsFilesBasePath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/annotations/'\n",
        "labelMapPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/label_map.pbtxt'\n",
        "testPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/test.txt'\n",
        "trainPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/train.txt'\n",
        "valPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/val.txt'\n",
        "\n",
        "\n",
        "\n",
        "%cd /root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/img"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data/mine\n",
            "/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDWZh00f_mar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  print(image.size)\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkbApV6M_mkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 8) ]\n",
        "TEST_IMAGE_PATHS = [ os.path.join(imageFilesBasePath, x) for x in os.listdir(imageFilesBasePath) ]\n",
        "print(TEST_IMAGE_PATHS)\n",
        "\n",
        "for img in TEST_IMAGE_PATHS:\n",
        "  assert os.path.isfile(img)\n",
        "  print(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9I4wt0GBwGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  print(image.shape)\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "        \n",
        "      #print(output_dict)\n",
        "        \n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wigcAmMgLUDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def resize_image(image_path=None):\n",
        "  #imageDest = Image.new(\"RGB\", (640, 480))\n",
        "  resizeImagePath = image_path.replace(\"/img/\", \"/img_coco/\")\n",
        "  if not os.path.isdir(os.path.dirname(resizeImagePath)):\n",
        "    os.mkdir(os.path.dirname(resizeImagePath))\n",
        "  \n",
        "  imageSrc = Image.open(image_path)\n",
        "  imageDest = imageSrc.resize((640, 480), Image.LANCZOS)\n",
        "  \n",
        "  return imageDest\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKNyJVNKs_Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_image():\n",
        "  #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7tZjuNYB1Vp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "04cffc4a-3fed-4f35-8c4e-41b1d012d965"
      },
      "source": [
        "IMAGE_SIZE = (12, 8)\n",
        "from google.colab import files\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS[:1]:\n",
        "  if not image_path.endswith(\".jpg\"):\n",
        "    continue\n",
        "\n",
        "  print(image_path)\n",
        "  #image = Image.open(image_path)\n",
        "  image = resize_image(image_path)\n",
        "  print(\"Image Dimensions: {} {}\".format(image.width, image.height))\n",
        "  print(image_path)\n",
        "  print(detection_graph)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "  #print(output_dict)\n",
        "  if output_dict is None:\n",
        "    continue\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  \n",
        "  #plt.figure(figsize=IMAGE_SIZE)\n",
        "  #plt.imshow(image_np_expanded)\n",
        "  \n",
        "  saveImage = image_path.replace(\"/img/\", \"/img_labels/\")\n",
        "  if not os.path.isdir(os.path.dirname(saveImage)):\n",
        "    os.mkdir(os.path.dirname(saveImage))\n",
        "    \n",
        "  img = Image.fromarray(image_np_expanded, 'RGB')\n",
        "  img.save(saveImage)\n",
        "  files.download(saveImage)\n",
        "  \n",
        "  "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/img/img_0172.jpg\n",
            "Image Dimensions: 640 480\n",
            "/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/img/img_0172.jpg\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f8bd5e96438>\n",
            "(640, 480)\n",
            "(1, 480, 640, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c7c2cca6b887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2427\u001b[0m         \u001b[0mndmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many dimensions: %d > %d.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Too many dimensions: 4 > 3."
          ]
        }
      ]
    }
  ]
}