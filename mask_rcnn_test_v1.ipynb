{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask_rcnn_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbbarclay/mine/blob/master/mask_rcnn_test_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x27_0GMmJvj2",
        "colab_type": "code",
        "outputId": "44be3647-3fb0-4217-8a67-e01fb1d6402a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%mkdir /root/data\n",
        "%cd /root/data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuiGSNtfK8Xq",
        "colab_type": "code",
        "outputId": "dd25c8fc-c5d1-45a4-b1f6-6a73f4caee94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd /root/data\n",
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data\n",
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 119.40 MiB | 44.14 MiB/s, done.\n",
            "Resolving deltas: 100% (568/568), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyvDLhohMn0r",
        "colab_type": "code",
        "outputId": "318b76c3-73e9-4da8-c6cf-a08cbffd3734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/root/data/Mask_RCNN\")\n",
        "%cd /root/\n",
        "\n",
        "import mrcnn"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfZcGgwk1F4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "850a53c7-55be-4d58-ec6f-64330fd22c23"
      },
      "source": [
        "%mkdir -p /content/workspace\n",
        "%cd /content/workspace\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!rm -rf /content/local_drive\n",
        "!mkdir -p /content/local_drive/\n",
        "!cp -r /content/drive/My\\ Drive/MachineLearning /content/local_drive\n",
        "%ls"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workspace\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9H2OeadSxJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bb9d546f-9afc-4737-ad59-e5e1ed087734"
      },
      "source": [
        "%cd /content/local_drive/MachineLearning/trainingSets/someVids/srcVids\n",
        "%ls"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/local_drive/MachineLearning/trainingSets/someVids/srcVids\n",
            "'Cooper Station Scene.mp4'\n",
            " dune_trailer_1984_360p.mp4\n",
            " family_reunion_and_farewell_ezra_and_thrawn_star_wars_rebels_disney_xd.mp4\n",
            " IMG_0054.MOV\n",
            " IMG_0357.MOV\n",
            " IMG_1638.MOV\n",
            " interstellar1.mp4\n",
            "'Interstellar - Atmospheric Entry Scene 1080p HD.mp4'\n",
            " jim_gaffigan_obsessed_weddings.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCUY1zemMFMZ",
        "colab_type": "code",
        "outputId": "482e96a3-f8a2-44b5-ba22-3439e06f6d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/root/data/Mask_RCNN\")\n",
        "\n",
        "from mrcnn import utils\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to /root/data/Mask_RCNN/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVErECz8OciG",
        "colab_type": "code",
        "outputId": "dcfed277-5f05-4e12-bfad-48ddebf2eb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqlKm4lQOh1u",
        "colab_type": "code",
        "outputId": "bbde7942-e084-47f5-d29d-bcc33a7f1192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /root/data/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNgU-f2OsUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL73cElR2CX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2bc92d5b-8fe3-44f9-e08a-e7cc04234adf"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/MachineLearning/trainingSets/myRandomStuff_v1/ml_training/\n",
        "%ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/trainingSets/myRandomStuff_v1/ml_training\n",
            "_DSC5197.jpg  _DSC6277.jpg  _DSC6404.jpg  _MG_0066.jpg  _MG_9836.jpg\n",
            "_DSC5205.jpg  _DSC6282.jpg  _DSC6417.jpg  _MG_0073.jpg  _MG_9840.jpg\n",
            "_DSC5206.jpg  _DSC6312.jpg  _DSC6462.jpg  _MG_0524.jpg  _MG_9844.jpg\n",
            "_DSC6260.jpg  _DSC6339.jpg  _DSC6563.jpg  _MG_9832.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lpBpYxX_xUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Forked form the visualize module as I want to save out the results of this function (I need it to return the reulst.)\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import itertools\n",
        "import colorsys\n",
        "\n",
        "import numpy as np\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches,  lines\n",
        "from matplotlib.patches import Polygon\n",
        "import IPython.display\n",
        "\n",
        "def display_and_return_instances(image, boxes, masks, class_ids, class_names,\n",
        "                        scores=None, title=\"\",\n",
        "                        figsize=(16, 16), ax=None,\n",
        "                        show_mask=True, show_bbox=True,\n",
        "                        colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    #if not ax:\n",
        "    #    _, ax = plt.subplots(1, figsize=figsize)\n",
        "    #    auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or visualize.random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    #ax.set_ylim(height + 10, -10)\n",
        "    #ax.set_xlim(-10, width + 10)\n",
        "    #ax.axis('off')\n",
        "    #ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            #ax.add_patch(p)\n",
        "\n",
        "        # Label\n",
        "        if not captions:\n",
        "            class_id = class_ids[i]\n",
        "            score = scores[i] if scores is not None else None\n",
        "            label = class_names[class_id]\n",
        "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
        "        else:\n",
        "            caption = captions[i]\n",
        "        #ax.text(x1, y1 + 8, caption,\n",
        "        #        color='w', size=11, backgroundcolor=\"none\")\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            #ax.add_patch(p)\n",
        "    #ax.imshow(masked_image.astype(np.uint8))\n",
        "    #if auto_show:\n",
        "    #    plt.show()\n",
        "        \n",
        "    return masked_image.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6SjyaPB5S-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Video prep IMG_0357\n",
        "!mkdir -p /content/drive/My\\ Drive/MachineLearning/trainingSets/someVids/frames/IMG_0357/\n",
        "!mkdir -p /content/drive/My\\ Drive/MachineLearning/trainingSets/someVids/inference/IMG_0357/\n",
        "!ffmpeg -i \"/content/drive/My Drive/MachineLearning/trainingSets/someVids/IMG_0357.MOV\"  \"/content/drive/My Drive/MachineLearning/trainingSets/someVids/frames/IMG_0357/IMG_0357.%04d.jpg\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoaNqg5GTAqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "ea2842e9-83a7-4479-eac4-f93cf2bc5aa9"
      },
      "source": [
        "%cd /content/local_drive/MachineLearning/trainingSets/someVids/\n",
        "\n",
        "%cd IMG_0357/frames\n",
        "\n",
        "\n",
        "!ffmpeg -r 25 -f image2 -i inference.%04d.jpg -vcodec libx264 -crf 10 -pix_fmt yuv420p IMG_0357.mp4"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/local_drive/MachineLearning/trainingSets/someVids\n",
            "/content/local_drive/MachineLearning/trainingSets/someVids/IMG_0357/frames\n",
            "ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from 'inference.%04d.jpg':\n",
            "  Duration: 00:00:07.92, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x55d46e0bc000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mprofile High, level 4.0\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=10.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'IMG_0357.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  198 fps=4.5 q=-1.0 Lsize=   29392kB time=00:00:07.80 bitrate=30868.9kbits/s speed=0.175x    \n",
            "video:29389kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.010813%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mframe I:2     Avg QP:10.52  size:204578\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mframe P:81    Avg QP:11.53  size:152391\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mframe B:115   Avg QP:12.57  size:150788\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mconsecutive B-frames: 15.2% 17.2% 15.2% 52.5%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mmb I  I16..4: 24.7% 70.7%  4.6%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mmb P  I16..4:  9.8% 47.7%  5.4%  P16..4:  9.6% 12.1% 15.1%  0.0%  0.0%    skip: 0.3%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mmb B  I16..4:  3.1% 21.3%  7.8%  B16..8:  9.8% 22.9% 17.1%  direct:17.4%  skip: 0.5%  L0:50.8% L1:40.8% BI: 8.4%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0m8x8 transform intra:71.8% inter:94.6%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mcoded y,uvDC,uvAC intra: 69.9% 71.6% 33.5% inter: 37.1% 81.7% 19.9%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mi16 v,h,dc,p: 43% 32% 23%  1%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 20% 34%  4%  2%  3%  2%  4%  5%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 27% 10%  3%  3%  4%  3%  4%  3%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mi8c dc,h,v,p: 28% 28% 38%  5%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mref P L0: 47.4% 13.5% 23.4% 15.8%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mref B L0: 71.1% 22.7%  6.3%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mref B L1: 91.5%  8.5%\n",
            "\u001b[1;36m[libx264 @ 0x55d46d819e00] \u001b[0mkb/s:30397.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9HyUO5bdMfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"IMG_0357.mp4\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi0GvdWgOzHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "from PIL import Image\n",
        "import numpy\n",
        "import re\n",
        "\n",
        "# Load a random image from the images folder\n",
        "VID_DIR = \"/content/local_drive/MachineLearning/trainingSets/someVids/srcVids\"\n",
        "FRAMES_DIR = \"/content/local_drive/MachineLearning/trainingSets/someVids/FRAMES\"\n",
        "OUT_DIR = \"/content/local_drive/MachineLearning/trainingSets/someVids/OUT\"\n",
        "\n",
        "    \n",
        "escaped_vid = VID_DIR.replace(\" \", \"\\ \")\n",
        "print(escaped_vid)\n",
        "\n",
        "\n",
        "srcVids = os.listdir(VID_DIR)\n",
        "\n",
        "for vid in srcVids:\n",
        "    print(vid)\n",
        "    print(\"#\"*80)\n",
        "    print(\"  ----- Decoding ----\")\n",
        "    print(\"#\"*80)\n",
        "    \n",
        "    image_path = os.path.join(VID_DIR, vid)\n",
        "    print(image_path)\n",
        "    image_base, image_extension = vid.split(\".\")\n",
        "\n",
        "    if image_extension not in [\"mov\", \"mp4\", \"MOV\"]:\n",
        "        continue\n",
        "        \n",
        "    print(image_base, image_extension)\n",
        "    print(\"image_path\", image_path)\n",
        "    escaped_path = image_path.replace(\" \", \"\\ \")\n",
        "    escaped_out_path_tokens = escaped_path.split(\".\")\n",
        "    escaped_out_path = os.path.join(escaped_out_path_tokens[0] + \"/frames/tmp.%05d.jpg\")\n",
        "    escaped_out_dir = os.path.dirname(escaped_out_path)\n",
        "    escaped_final_path = \"{}_inference.mp4\".format(escaped_out_path_tokens[0].replace(\"srcVids\", \"inferenceVids\"))\n",
        "    print(\"escaped_path\", escaped_path)\n",
        "    print(\"escaped_out_path\", escaped_out_path)\n",
        "    print(\"escaped_out_dir\", escaped_out_dir)\n",
        "    \n",
        "    !mkdir -p $escaped_out_dir\n",
        "    print(\"ffmpeg -i {0} {1}\".format(escaped_path, escaped_out_path))\n",
        "    !ffmpeg -i $escaped_path $escaped_out_path \n",
        "    \n",
        "    unescaped = escaped_out_dir.replace(\"\\ \", \" \")\n",
        "    #for f in next(os.walk(unescaped))[2]:\n",
        "    sortedFiles = os.listdir(unescaped)\n",
        "    sortedFiles.sort()\n",
        "    \n",
        "    baseOutputDirectory = None\n",
        "    \n",
        "    print(\"#\"*80)\n",
        "    print(\"  ----- Inference ----\")\n",
        "    print(\"#\"*80)\n",
        "    print(sortedFiles)\n",
        "    for f in sortedFiles:\n",
        "        image_path = os.path.join(unescaped, f)\n",
        "        print(\"image_path: \", image_path)\n",
        "        assert os.path.isfile(image_path)\n",
        "\n",
        "        if not image_path.endswith(\"jpg\"):\n",
        "            continue\n",
        "            \n",
        "        #if not \"inference\" in image_path:\n",
        "        #    continue\n",
        "            \n",
        "        image = skimage.io.imread(image_path)\n",
        "\n",
        "        #Run detection\n",
        "        results = model.detect([image], verbose=1)\n",
        "\n",
        "        #Visualize results\n",
        "        r = results[0]\n",
        "        result = display_and_return_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                                    class_names, r['scores'], show_bbox=False)\n",
        "    \n",
        "        imgToSave = Image.fromarray(result, 'RGB')\n",
        "        savePath = image_path.replace(\"tmp\", \"inference\")\n",
        "\n",
        "        imgToSave.save(savePath)\n",
        "        print(\"Saving: \", savePath)\n",
        "        baseOutputDirectory = savePath\n",
        "        print(baseOutputDirectory)\n",
        "\n",
        "        \n",
        "    print(baseOutputDirectory)\n",
        "    if not baseOutputDirectory:\n",
        "        continue\n",
        "    \n",
        "    \n",
        "    print(\"#\"*80)\n",
        "    print(\"  ----- Encoding ----\")\n",
        "    print(\"#\"*80)\n",
        "    dst_tokens = baseOutputDirectory.split(\".\")\n",
        "    savePath = \"{}.%05d.jpg\".format(dst_tokens[0])\n",
        "    print(dst_tokens)\n",
        "    print(savePath)\n",
        "    escaped_inference_path = baseOutputDirectory.replace(\" \", \"\\ \")\n",
        "    escaped_inference_dir = os.path.dirname(escaped_inference_path)\n",
        "    !mkdir -p $escaped_inference_dir\n",
        "    print(\"Final source frames: {0}\".format(escaped_inference_path))\n",
        "    print(\"Generating final at: {0}\".format(escaped_final_path))\n",
        "    print(\"Escaped inference path: \", escaped_inference_path)\n",
        "    !ffmpeg -r 25 -f image2 -i $escaped_inference_path -vcodec libx264 -crf 10 -pix_fmt yuv420p $escaped_final_path\n",
        "    \n",
        "    !cp $escaped_final_path /content/drive/My\\ Drive/MachineLearning/trainingSets/someVids/inferenceVids\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx2gORKFvDgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = \"/content/local_drive/MachineLearning/trainingSets/someVids/IMG_0357/frames/inference.%04d.jpg\" \n",
        "p2 = \"/content/local_drive/MachineLearning/trainingSets/someVids/IMG_0357_inference.mp4\"\n",
        "\n",
        "!ffmpeg -r 25 -f image2 -i $p1 -vcodec libx264 -crf 10 -pix_fmt yuv420p $p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gI1HCJj7qFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c1de574f-2d71-4fda-9ce5-178c92819376"
      },
      "source": [
        "%cd /content/local_drive/MachineLearning/trainingSets/someVids/inferenceVids\n",
        "%ls\n",
        "\n",
        "!cp -r /content/local_drive/MachineLearning/trainingSets/someVids/inferenceVids/ /content/drive/My\\ Drive/MachineLearning/trainingSets/someVids/"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/local_drive/MachineLearning/trainingSets/someVids/inferenceVids\n",
            "'Cooper Station Scene_inference.mp4'\n",
            " dune_trailer_1984_360p_inference.mp4\n",
            " family_reunion_and_farewell_ezra_and_thrawn_star_wars_rebels_disney_xd_inference.mp4\n",
            " \u001b[0m\u001b[01;34mIMG_0357\u001b[0m/\n",
            " IMG_0357_inference.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3goPDPzuuMuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91730d81-600c-41bb-92be-dca8b9674e91"
      },
      "source": [
        "!cp /content/local_drive/MachineLearning/trainingSets/someVids/inference /content/drive/My\\ Drive/MachineLearning/trainingSets/someVids/inference"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: -r not specified; omitting directory '/content/local_drive/MachineLearning/trainingSets/someVids/inference'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzZJt3EuwXRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "d0b9985f-f43e-48a4-944a-674f0ee16b16"
      },
      "source": [
        "%ls /content/local_drive/MachineLearning/trainingSets/someVids/\n",
        "\n",
        "files.download('/content/local_drive/MachineLearning/trainingSets/someVids/Cooper Station Scene_inference.mp4')"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'Cooper Station Scene'\u001b[0m/\n",
            "'Cooper Station Scene.mp4'\n",
            " dune_trailer_1984_360p.mp4\n",
            "\u001b[01;34m'Every hour we spend on that planet will be seven years back on earth'\u001b[0m/\n",
            " \u001b[01;34mIMG_0054\u001b[0m/\n",
            " IMG_0054.MOV\n",
            " \u001b[01;34mIMG_0357\u001b[0m/\n",
            " \u001b[01;34mIMG_0357_inference\u001b[0m/\n",
            " IMG_0357.MOV\n",
            " \u001b[01;34mIMG_1638\u001b[0m/\n",
            " IMG_1638.MOV\n",
            " \u001b[01;34minference\u001b[0m/\n",
            " interstellar1.mp4\n",
            "\u001b[01;34m'Interstellar - Atmospheric Entry Scene 1080p HD'\u001b[0m/\n",
            "'Interstellar - Atmospheric Entry Scene 1080p HD.mp4'\n",
            "\u001b[01;34m'Interstellar - Cooper Station Scene 1080p HD'\u001b[0m/\n",
            " jim_gaffigan_obsessed_weddings.mp4\n",
            "'y2mate.com - family_reunion_and_farewell_ezra_and_thrawn_star_wars_rebels_disney_xd_n1pmZ61M6x8_1080p.mp4'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-b72cf01a90f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls /content/local_drive/MachineLearning/trainingSets/someVids/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/local_drive/MachineLearning/trainingSets/someVids/Cooper Station Scene_inference.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_threading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/local_drive/MachineLearning/trainingSets/someVids/Cooper Station Scene_inference.mp4"
          ]
        }
      ]
    }
  ]
}