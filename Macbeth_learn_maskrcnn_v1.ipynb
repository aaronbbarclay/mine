{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Macbeth_learn_maskrcnn_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbbarclay/mine/blob/master/Macbeth_learn_maskrcnn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zafzl1Ptq2",
        "colab_type": "text"
      },
      "source": [
        "Using mask RCNN to train macbeth detection\n",
        "\n",
        "https://github.com/matterport/Mask_RCNN/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMcC41nfjCd",
        "colab_type": "code",
        "outputId": "fab676df-fc97-4874-e555-30174f4b3b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: protobuf, termcolor, absl-py, wheel, keras-applications, grpcio, numpy, astor, tensorflow-estimator, gast, tensorboard, keras-preprocessing, six\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dR8HxrO_oI7",
        "colab_type": "code",
        "outputId": "86e9400a-8bf9-4a27-8b75-b6bcdabb01c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "source": [
        "%cd /root/\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!git clone --quiet https://github.com/matterport/Mask_RCNN/\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 1,818 kB of archives.\n",
            "After this operation, 7,688 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pil amd64 5.1.0-1 [328 kB]\n",
            "Fetched 1,818 kB in 0s (4,184 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 130912 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJh-6EXuryi",
        "colab_type": "code",
        "outputId": "0346a071-350c-473d-aaab-a29a7f0cce52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!mkdir -p /content/drive/\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES-su46RRN_X",
        "colab_type": "code",
        "outputId": "ba5ea5b6-64bb-4767-9460-201c26aee4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "######\n",
        "# Only do this once as the trainied model is stored in this file. -- now stored in google drive\n",
        "######\n",
        "\n",
        "#!mkdir -p /root/data\n",
        "#%cd /content/drive/My\\ Drive/MachineLearning/projects/macbethIdentify_v1\n",
        "#!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "--2019-06-08 11:45:50--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-06-08 11:45:50--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.10.11\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.10.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  63.2MB/s    in 4.1s    \n",
            "\n",
            "2019-06-08 11:45:55 (59.2 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSlGKXeL_pzS",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "## This is not needed\n",
        "\n",
        "### Install pycotools\n",
        "##!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRULdCfrA39Y",
        "colab_type": "code",
        "outputId": "4932e0d4-efaf-4f7d-d0ab-9fcfac959790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is not needed\n",
        "\n",
        "# Compile protocol buffers\n",
        "#%cd ~/models/research\n",
        "#!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khuHLMHuMqAB",
        "colab_type": "code",
        "outputId": "8f127af0-d6f3-4dbc-b927-fcbe1823f436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /root/Mask_RCNN/\n",
        "%ls\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/root/Mask_RCNN/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/  LICENSE      \u001b[01;34mmrcnn\u001b[0m/     requirements.txt  setup.cfg\n",
            "\u001b[01;34mimages\u001b[0m/  MANIFEST.in  README.md  \u001b[01;34msamples\u001b[0m/          setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhhQJov6MM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import six\n",
        "import mrcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB5fbc3_piye",
        "colab_type": "code",
        "outputId": "43123c9a-3522-4538-ad9f-293cb688658a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/drive/My\\ Drive/\n",
        "%cd MachineLearning/projects/macbethIdentify_v1/data/img/\n",
        "\n",
        "\n",
        "BASEDIR = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\"\n",
        "print(os.path.isdir(BASEDIR))\n",
        "print(BASEDIR)\n",
        "\n",
        "WEIGHTS_FILE = \"{0}/{1}\".format(BASEDIR, \"mask_rcnn_coco.h5\")\n",
        "LOG_DIR = \"{0}/{1}\".format(BASEDIR, \"LOGS\")\n",
        "imageFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img\")\n",
        "maskFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/mask_images\")\n",
        "valFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img_val\")\n",
        "#annotationsFilesBasePath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/data/data/annotations/'\n",
        "#labelMapPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/label_map.pbtxt'\n",
        "#testPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/test.txt'\n",
        "#trainPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/train.txt'\n",
        "#valPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/val.txt'\n",
        "\n",
        "print(imageFilesBasePath)\n",
        "print(maskFilesBasePath)\n",
        "print(valFilesBasePath)\n",
        "print(os.path.isdir(imageFilesBasePath))\n",
        "print(os.path.isdir(maskFilesBasePath))\n",
        "print(os.path.isdir(valFilesBasePath))\n",
        "print(os.path.isfile(WEIGHTS_FILE))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/img\n",
            "True\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/mask_images\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img_val\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-0tqfOiySx7",
        "colab": {}
      },
      "source": [
        "def getImageFromDir(basePath=None, filename=None, className=None):\n",
        "    name, ext = filename.split(\".\")\n",
        "    dirContents = os.listdir(basePath)\n",
        "    for f in dirContents:\n",
        "        maskName, maskExtension = f.split('.')\n",
        "        #print(\"Has className: \", f, \" \" , className, \" \", className in f)\n",
        "        if f.startswith(name) and className in f:\n",
        "            #print(os.path.join(basePath, f))\n",
        "            return os.path.join(basePath, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0nJZtNoE02X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getExif(image=None, key=None):\n",
        "    \"\"\"\n",
        "    Returns a tuple of exif key and exif value\n",
        "    \"\"\"\n",
        "    for (k, v) in PIL.ExifTags.TAGS.items():\n",
        "        if v.lower() == key:\n",
        "            #print(v.lower(), \" \", key)\n",
        "            if image._getexif():\n",
        "                return (k, image._getexif()[k])\n",
        "            else:\n",
        "                return (k, 1)\n",
        "    \n",
        "def fixOrientation(image=None, orientation=1):\n",
        "\n",
        "    result = image\n",
        "    #print(orientation)\n",
        "    if orientation == 3 : \n",
        "        result =  image.rotate(180, expand=True)\n",
        "    elif orientation == 6 : \n",
        "        result = image.rotate(270, expand=True)\n",
        "    elif orientation == 8 : \n",
        "        result = image.rotate(90, expand=True)\n",
        "        \n",
        "    return result\n",
        "\n",
        "def isValidImage(filename=None):\n",
        "    BLACKLIST = [\"kaztest.jpg\"]\n",
        "    VALID_EXTENSIONS = [\"jpg\", \"png\"]\n",
        "    name, extension = filename.split(\".\")\n",
        "    \n",
        "    if extension.lower() not in VALID_EXTENSIONS:\n",
        "        return False\n",
        "    \n",
        "    if filename in BLACKLIST:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "                        \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBbV9Tora90P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "import numpy as np\n",
        "\n",
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uE2h-mZc3MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class CocoConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 80\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "cocoConfig = CocoConfig()\n",
        "#cocoConfig.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJNOAQTYDgu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coco Inference Config\n",
        "\n",
        "class InferenceCocoConfig(CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "\n",
        "inferenceCocoConfig = InferenceCocoConfig()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25S69brw8Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Run inference on images \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "from PIL import Image\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=inferenceCocoConfig,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = WEIGHTS_FILE\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "    \n",
        "    \n",
        "RESULTS = []\n",
        "\n",
        "for imageFilename in os.listdir(imageFilesBasePath)[20:30]:\n",
        "    if not isValidImage(imageFilename):\n",
        "        continue\n",
        "    \n",
        "    imagePath = os.path.join(imageFilesBasePath, imageFilename)\n",
        "    maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")\n",
        "\n",
        "    if not maskPath:\n",
        "        continue\n",
        "    \n",
        "    _image = skimage.io.imread(imagePath)    \n",
        "    _resizeResult = utils.resize_image(_image, max_dim=1024)\n",
        "    _scale = _resizeResult[2]\n",
        "    _padding = _resizeResult[3]\n",
        "    _crop = _resizeResult[4]\n",
        "    imageSrc = _resizeResult[0]\n",
        "    #imageSrc = utils.resize_image(Image.open(imagePath),max_dim=1024)\n",
        "    _maskSrc = skimage.io.imread(maskPath)  #Image.open(maskPath)\n",
        "    \n",
        "    print(_maskSrc.shape)\n",
        "    print(_image.shape)\n",
        "    \n",
        "    _maskTmp = np.expand_dims(_maskSrc, axis=2)\n",
        "    _maskTmp2 = np.tile(_maskTmp, 3)\n",
        "    #_maskTmp = np.tile(_maskSrc, 3)\n",
        "    print (_maskTmp2.shape)\n",
        "    \n",
        "    print(\"####\")\n",
        "    #print(_image.shape)\n",
        "    #print(_maskSrc.shape)\n",
        "    print(_scale, _padding, _crop)\n",
        "    print(_maskSrc)\n",
        "    maskSrc = utils.resize_mask(_maskTmp2, _scale, _padding, _crop)\n",
        "    print(maskSrc.shape)\n",
        "\n",
        "    #orientation = getExif(imageSrc, \"orientation\")\n",
        "    #imageOrientated = fixOrientation(imageSrc, orientation[1])\n",
        "    image = Image.fromarray(imageSrc)\n",
        "    maskImage = Image.fromarray(maskSrc)\n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = image.split()\n",
        "    channelsMask = maskImage.split()\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], channelsMask[0])\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "        \n",
        "    imageArray = numpy.array(imageSrc)\n",
        "\n",
        "    \n",
        "    #plt.figure(figsize=(8, 6))\n",
        "    #plt.title(imagePath.split(\"/\").pop())\n",
        "    #plt.imshow(newImage)\n",
        "    \n",
        "    result = model.detect([imageArray], verbose=1)[0]\n",
        "    RESULTS.append(result)\n",
        "    splash = color_splash(imageArray, result[\"masks\"])\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(result[\"class_ids\"])\n",
        "    plt.imshow(splash)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U35sKd8mUUnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Macbeth Config\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class MacbethConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"macbeth\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = MacbethConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCSAPTkbX5mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(BASEDIR)\n",
        "\n",
        "# URL from which to download the latest COCO trained weights\n",
        "COCO_MODEL_URL = \"https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "#imageFilesBasePath = \"/root/data/mine/machineLearning/macbethIdentify/data/data/img\"\n",
        "maskFilesBasePath = maskFilesBasePath\n",
        "\n",
        "\n",
        "# Dataset\n",
        "class MacbethDataset(utils.Dataset):\n",
        "    def load_macbeths(self, dataset_dir, subset):\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"macbeth\", 1, \"macbeth\")\n",
        "        \n",
        "        i = 0\n",
        "        for imageFilename in os.listdir(dataset_dir)[:5]:\n",
        "            if not isValidImage(imageFilename):\n",
        "                continue\n",
        "    \n",
        "            imagePath = os.path.join(dataset_dir, imageFilename)\n",
        "            maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")  \n",
        "            \n",
        "            if not maskPath:\n",
        "                continue\n",
        "                \n",
        "            #assert os.path.isfile(imagePath)\n",
        "            #assert os.path.isfile(maskPath)\n",
        "            #print(imagePath)\n",
        "            #print(maskPath)\n",
        "            #print(os.path.isfile(maskPath))\n",
        "            if not os.path.isfile(imagePath):\n",
        "                continue\n",
        "                \n",
        "            if not os.path.isfile(maskPath):\n",
        "                continue\n",
        "                \n",
        "\n",
        "            _image = skimage.io.imread(imagePath)\n",
        "            image = utils.resize_image(_image, max_dim=1024)[0]\n",
        "            height, width = image.shape[:2]\n",
        "            print(width, height)\n",
        "            print(\"Adding: \", imagePath)\n",
        "            #print(\"Adding: \", maskPath)\n",
        "            self.add_image(\n",
        "                \"macbeth\",\n",
        "                image_id=i,\n",
        "                path=imagePath,\n",
        "                width=width,\n",
        "                height=height\n",
        "            )\n",
        "            self._image_ids.append(i)\n",
        "            i += 1\n",
        "        \n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        \n",
        "        maskPath = getImageFromDir(maskFilesBasePath, self.image_info[image_id][\"path\"].split(\"/\").pop(), \"macbeth\")  \n",
        "        #print(maskPath)\n",
        "        assert os.path.isfile(maskPath)\n",
        "\n",
        "        # I think this is width, height, number of instances\n",
        "        mask = np.zeros([self.image_info[image_id][\"width\"], self.image_info[image_id][\"height\"], 1], dtype=np.uint8)\n",
        "        _maskSrc = skimage.io.imread(maskPath)\n",
        "        print(maskSrc)\n",
        "        maskSrc = utils.resize_image(_maskSrc, max_dim=1024)[0]\n",
        "        maskArray = numpy.array(maskSrc)\n",
        "        \n",
        "        print(\"msh:\", mask.shape)\n",
        "        print(\"ma:\", maskArray.shape)\n",
        "        \n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "    \n",
        "        \n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"macbeth\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcb-VNdcyyYW",
        "colab_type": "code",
        "outputId": "438c4b47-9041-4fe9-f2e4-de5cdb134aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(BASEDIR)\n",
        "print(maskFilesBasePath)\n",
        "print(imageFilesBasePath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/mask_images\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPQcbYWaPUl",
        "colab_type": "code",
        "outputId": "fb92899f-a136-4da6-f770-05b81ed6788e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# test stuff\n",
        "testPath = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00135.jpg\"\n",
        "#mask = np.zeros([1000, 2000, 1], dtype=np.uint8)\n",
        "\n",
        "#test = MacbethDataset()\n",
        "#test.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "#array = test.load_image(1)\n",
        "\n",
        "#print(type(array))\n",
        "#print(type(mask))\n",
        "\n",
        "#print(array.shape)\n",
        "\n",
        "image = skimage.io.imread(testPath)\n",
        "\n",
        "print(image.shape)\n",
        "resized_image = utils.resize_image(image, max_dim=1024)\n",
        "print(resized_image[0].shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1869, 1400, 3)\n",
            "(1024, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1K36Et6c6BI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "810ce4b0-ddb1-485a-8511-fd12d1b0c06e"
      },
      "source": [
        "#\n",
        "# Visualise image and matte overlays are working through the dataset class\n",
        "#\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "\n",
        "\n",
        "for i, f in enumerate(dataset_train.image_ids):\n",
        "    \n",
        "    #_img = dataset_train.load_image\n",
        "    img = Image.fromarray(dataset_train.load_image(f))\n",
        "    #tst = dataset_train.load_image(f)\n",
        "    #print(tst.dtype)\n",
        "    #img2 = utils.resize_image(img, max_dim=1024)\n",
        "    \n",
        "    mask = Image.fromarray(dataset_train.load_mask(f)[1])\n",
        "    \n",
        "    print(\"shape: \", img.size)\n",
        "    print(\"shape: \", mask.size)\n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = img.split()\n",
        "    #print(channels)\n",
        "    #print(mask)\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], mask)\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(\"banana\")\n",
        "    plt.imshow(newImage)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1024 1024\n",
            "Adding:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00135.jpg\n",
            "1024 1024\n",
            "Adding:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00106.jpg\n",
            "1024 1024\n",
            "Adding:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/2_associates_00002.jpg\n",
            "1024 1024\n",
            "Adding:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/6associates_bluetest.jpg\n",
            "1024 1024\n",
            "Adding:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/mg_0008.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-db2939a0b042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#img2 = utils.resize_image(img, max_dim=1024)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-0d2ef7716a88>\u001b[0m in \u001b[0;36mload_mask\u001b[0;34m(self, image_id)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0m_maskSrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskSrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmaskSrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_maskSrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmaskArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskSrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'maskSrc' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_x2OICY4lvd",
        "colab_type": "code",
        "outputId": "7e213d60-77b4-43fd-b0df-103e70cefc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "imageFilesBasePath"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX9GlLlfikA",
        "colab_type": "code",
        "outputId": "bf5db0a0-dd99-492d-c329-a09157d98810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "#\n",
        "# Perform Training\n",
        "#\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "print(\"FSFDFDF\")\n",
        "\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "#dataset_val = MacbethDataset()\n",
        "#dataset_val.load_macbeths(\"/root/data/mine/machineLearning/macbethIdentify/data/data/img_val\", \"val\")\n",
        "#dataset_val.prepare()\n",
        "\n",
        "print(\"Training network heads\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "           learning_rate=config.LEARNING_RATE,\n",
        "           epochs=30,\n",
        "           layers='heads')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ab96180e5a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_LOGS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FSFDFDF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacbethDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2463\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2464\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2465\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \"\"\"\n\u001b[1;32m   1761\u001b[0m     assign = state_ops.assign(self._variable, value, use_locking=use_locking,\n\u001b[0;32m-> 1762\u001b[0;31m                               name=name)\n\u001b[0m\u001b[1;32m   1763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    221\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    222\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMIy8eWoiJLN",
        "colab_type": "code",
        "outputId": "ea28761c-0dcb-4ee2-c99c-ebb939ec9489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%cd ~/data//mine/machineLearning/macbethIdentify/data/data/\n",
        "%ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data/mine/machineLearning/macbethIdentify/data/data\n",
            "total 48\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mannottions_json\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mimg\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 04:59 \u001b[01;34mimg_val\u001b[0m/\n",
            "-rwx------ 1 root root    34 Apr 27 03:50 \u001b[01;32mlabel_map.pbtxt\u001b[0m*\n",
            "drwx------ 2 root root 16384 May 26 05:05 \u001b[01;34mmask_images\u001b[0m/\n",
            "-rwx------ 1 root root   127 Apr  9 00:21 \u001b[01;32mtest.txt\u001b[0m*\n",
            "-rwx------ 1 root root  1031 Apr 27 03:50 \u001b[01;32mtrain.txt\u001b[0m*\n",
            "-rwx------ 1 root root   141 Apr  9 00:21 \u001b[01;32mval.txt\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd4KUgaZMLl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}