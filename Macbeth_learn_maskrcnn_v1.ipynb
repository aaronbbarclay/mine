{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Macbeth_learn_maskrcnn_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbbarclay/mine/blob/master/Macbeth_learn_maskrcnn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zafzl1Ptq2",
        "colab_type": "text"
      },
      "source": [
        "Using mask RCNN to train macbeth detection\n",
        "\n",
        "https://github.com/matterport/Mask_RCNN/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMcC41nfjCd",
        "colab_type": "code",
        "outputId": "fab676df-fc97-4874-e555-30174f4b3b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: protobuf, termcolor, absl-py, wheel, keras-applications, grpcio, numpy, astor, tensorflow-estimator, gast, tensorboard, keras-preprocessing, six\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0cXN-OOKkVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dR8HxrO_oI7",
        "colab_type": "code",
        "outputId": "7a845203-d7f9-4256-a5a2-ab0031990840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "source": [
        "%cd /root/\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "#!git clone --quiet https://github.com/matterport/Mask_RCNN/\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 1,818 kB of archives.\n",
            "After this operation, 7,688 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pil amd64 5.1.0-1 [328 kB]\n",
            "Fetched 1,818 kB in 1s (1,265 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 130912 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "\u001b[K     |████████████████████████████████| 993kB 5.0MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJh-6EXuryi",
        "colab_type": "code",
        "outputId": "6afe357f-ed4e-4005-b8f3-5cd58e02b900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!mkdir -p /content/drive/\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONvvLz1uLM-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b93d12c-d245-4c89-aee0-b76a4213d925"
      },
      "source": [
        "%cd /root\n",
        "%ls\n",
        "!mv Mask_RCNN/ Mask_RCNN_old/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "\u001b[0m\u001b[01;34mMask_RCNN\u001b[0m/  \u001b[01;34mmodels\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz8xh55NKnbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df9e66df-22a7-4b8e-a810-a07cfd92725f"
      },
      "source": [
        "!mkdir -p /content/drive/My\\ Drive/MachineLearning/tools\n",
        "%cd /content/drive/My\\ Drive/MachineLearning/tools/\n",
        "!git clone --quiet https://github.com/matterport/Mask_RCNN/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES-su46RRN_X",
        "colab_type": "code",
        "outputId": "ba5ea5b6-64bb-4767-9460-201c26aee4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "######\n",
        "# Only do this once as the trainied model is stored in this file. -- now stored in google drive\n",
        "######\n",
        "\n",
        "#!mkdir -p /root/data\n",
        "#%cd /content/drive/My\\ Drive/MachineLearning/projects/macbethIdentify_v1\n",
        "#!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "--2019-06-08 11:45:50--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-06-08 11:45:50--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.10.11\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.10.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  63.2MB/s    in 4.1s    \n",
            "\n",
            "2019-06-08 11:45:55 (59.2 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSlGKXeL_pzS",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "## This is not needed\n",
        "\n",
        "### Install pycotools\n",
        "##!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRULdCfrA39Y",
        "colab_type": "code",
        "outputId": "4932e0d4-efaf-4f7d-d0ab-9fcfac959790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is not needed\n",
        "\n",
        "# Compile protocol buffers\n",
        "#%cd ~/models/research\n",
        "#!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khuHLMHuMqAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/drive/My Drive/MachineLearning/tools\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhhQJov6MM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ccfd1f7-9931-486a-ded9-309c6093cb44"
      },
      "source": [
        "%cd /\n",
        "import six\n",
        "import mrcnn"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB5fbc3_piye",
        "colab_type": "code",
        "outputId": "f4f32f65-8e34-4b79-8422-f043ce0a2aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/drive/My\\ Drive/\n",
        "%cd MachineLearning/projects/macbethIdentify_v1/data/img/\n",
        "\n",
        "\n",
        "BASEDIR = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\"\n",
        "print(os.path.isdir(BASEDIR))\n",
        "\n",
        "\n",
        "WEIGHTS_FILE = \"{0}/{1}\".format(BASEDIR, \"mask_rcnn_coco.h5\")\n",
        "LOG_DIR = \"{0}/{1}\".format(BASEDIR, \"LOGS\")\n",
        "imageFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img\")\n",
        "maskFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/mask_images\")\n",
        "valFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img_val\")\n",
        "\n",
        "ANNOTATION_DIR = \"{0}/data/annotations\".format(BASEDIR)\n",
        "JSON_DIR = \"{0}/data/annotations_json\".format(BASEDIR)\n",
        "JSON_FILE = \"{0}/via_region_data.json\".format(JSON_DIR)\n",
        "#annotationsFilesBasePath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/data/data/annotations/'\n",
        "#labelMapPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/label_map.pbtxt'\n",
        "#testPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/test.txt'\n",
        "#trainPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/train.txt'\n",
        "#valPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/val.txt'\n",
        "\n",
        "#print(imageFilesBasePath)\n",
        "#print(maskFilesBasePath)\n",
        "#print(valFilesBasePath)\n",
        "print(os.path.isdir(imageFilesBasePath))\n",
        "print(os.path.isdir(maskFilesBasePath))\n",
        "print(os.path.isdir(valFilesBasePath))\n",
        "print(os.path.isfile(WEIGHTS_FILE))\n",
        "print(os.path.isdir(ANNOTATION_DIR))\n",
        "print(os.path.isdir(JSON_DIR))\n",
        "print(os.path.isfile(JSON_FILE))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/img\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHVEpJ6g6bU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        },
        "outputId": "760279d9-574a-4cd0-9c2c-1fc3a9f20bc9"
      },
      "source": [
        "# Convert rectlabel annotation to maskrcnn json\n",
        "# This only needs to be run of new images are added to the dataset (and exported from rectlabel)\n",
        "\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allAnnotations = glob.glob(ANNOTATION_DIR + \"/*\")\n",
        "\n",
        "print(allAnnotations)\n",
        "\n",
        "class JsonAnnotation:\n",
        "    def __init__(self):\n",
        "        self.filename = None\n",
        "        #self.fileref = \"\"\n",
        "        #self.size = \"\"\n",
        "        #self.base64_img_data = \"\"\n",
        "        #self.file_attributes = {}\n",
        "        self.all_points_x = []\n",
        "        self.all_points_y = []\n",
        "        \n",
        "    def dict1(self):\n",
        "        d = {}\n",
        "        d[\"fileref\"] = \"\"\n",
        "        d[\"size\"] = 23232323\n",
        "        d[\"filename\"] = self.filename\n",
        "        d[\"base64_img_data\"] = \"\"\n",
        "        d[\"file_attributes\"] = {}\n",
        "        d[\"regions\"] = self.createRegions()\n",
        "        \n",
        "        return d\n",
        "    \n",
        "    def createRegions(self):\n",
        "        regions = {0 : {}}\n",
        "        regions[0] = {}\n",
        "        regions[0][\"shape_attributes\"] = {}\n",
        "        regions[0][\"shape_attributes\"][\"name\"] = \"polygon\"\n",
        "        regions[0][\"shape_attributes\"][\"region_attributes\"] = {}\n",
        "        regions[0][\"shape_attributes\"][\"all_points_x\"] = self.all_points_x\n",
        "        regions[0][\"shape_attributes\"][\"all_points_y\"] = self.all_points_y\n",
        "        \n",
        "        return regions      \n",
        "    \n",
        "    def getString(self):\n",
        "        return {self.filename: \"test\"}\n",
        "\n",
        "allJsonAnnotations = {}\n",
        "\n",
        "for a in allAnnotations:\n",
        "    #if not a.count(\"megan_rapinoe_mg_0013\"):\n",
        "    #    continue\n",
        "\n",
        "    print(a)\n",
        "    tree = ET.parse(a)\n",
        "    root = tree.getroot()\n",
        "    #print(root)\n",
        "    #print(root.find(\"folder\").text)\n",
        "    #print(root.find(\"object\").get(\"name\"))\n",
        "    #print()\n",
        "\n",
        "    jsonAnnotation = JsonAnnotation()\n",
        "    jsonAnnotation.filename = root.find(\"filename\").text \n",
        "\n",
        "    _object = root.find(\"object\")\n",
        "    name = _object.find(\"name\").text \n",
        " \n",
        "    for child in _object:\n",
        "        if child.tag != \"polygon\":\n",
        "            continue\n",
        "            \n",
        "        for point in child:\n",
        "            #print(point.tag, \": \", point.text)\n",
        "            if point.tag.count(\"x\"):\n",
        "                jsonAnnotation.all_points_x.append(int(point.text))\n",
        "            else:\n",
        "                jsonAnnotation.all_points_y.append(int(point.text))\n",
        "    \n",
        "    allJsonAnnotations[jsonAnnotation.filename] = jsonAnnotation.dict1()\n",
        "    \n",
        "    \n",
        "with open(JSON_FILE, 'w') as f:\n",
        "    result = json.dump(allJsonAnnotations, f)\n",
        "    \n",
        "#print(result)\n",
        "\n",
        "print(\"writing: \", JSON_FILE)\n",
        "#f = open(JSON_FILE, 'w')\n",
        "#f.write(result)\n",
        "\n",
        "    #annotation = root.tag\n",
        "    #\n",
        "    \n",
        "    #polygon = root.find(\"polygon\")\n",
        "\n",
        "    #print(root.find(\"filename\").text)\n",
        "    #print(polygon)\n",
        "    "
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "['/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/jeff_kolitch_00097-mos.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/penn_jillette_00106.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/kaztest.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_00023.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_mg_0013.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_mg_0100.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mg_0006.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mg_0008.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/p04.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/penn_jillette_00135.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/robert_benmosche_00011.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/rt2012_xboard_00012-mos.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg11.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg13.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg8.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/t-7797r.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/2_associates_00002.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/2013_rt_cover_brian_rogers_00001-mos.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/6associates_bluetest.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/7.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5533_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5545_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/ARMAFC.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bob_amsterdam_00052.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bobby_flay_00217.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bobby_flay_00254.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/brendan_haircut_00001.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bts1.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00074.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00331-mos.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00461.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/deb1.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/girl-with-colorchecker.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/img_0172.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0319_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0341_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0475_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0481_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0750_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1309 2.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1310.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1311.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1312.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1313.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1314.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1315.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1316.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1317.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1318.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1319.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1320.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1321.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1322.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1323.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1324.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1325.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1326.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1327.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1328.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1329.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1330.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1331.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1332.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1333.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1335.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1336.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1337.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1338.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1339.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1340.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1341.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1342.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1343.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1344.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1346.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1347.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1348.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1349.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1334.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5595_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5611_orig.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1345.xml', '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mcc3-t.xml']\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/jeff_kolitch_00097-mos.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/penn_jillette_00106.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/kaztest.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_00023.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_mg_0013.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/megan_rapinoe_mg_0100.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mg_0006.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mg_0008.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/p04.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/penn_jillette_00135.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/robert_benmosche_00011.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/rt2012_xboard_00012-mos.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg11.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg13.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/sg8.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/t-7797r.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/2_associates_00002.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/2013_rt_cover_brian_rogers_00001-mos.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/6associates_bluetest.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/7.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5533_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5545_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/ARMAFC.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bob_amsterdam_00052.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bobby_flay_00217.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bobby_flay_00254.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/brendan_haircut_00001.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/bts1.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00074.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00331-mos.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/catherine_mary_stewart_00461.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/deb1.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/girl-with-colorchecker.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/img_0172.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0319_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0341_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0475_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0481_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_0750_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1309 2.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1310.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1311.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1312.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1313.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1314.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1315.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1316.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1317.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1318.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1319.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1320.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1321.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1322.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1323.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1324.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1325.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1326.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1327.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1328.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1329.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1330.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1331.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1332.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1333.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1335.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1336.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1337.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1338.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1339.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1340.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1341.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1342.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1343.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1344.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1346.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1347.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1348.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1349.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1334.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5595_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/8D5U5611_orig.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/IMG_1345.xml\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations/mcc3-t.xml\n",
            "writing:  /content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/annotations_json/via_region_data.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-0tqfOiySx7",
        "colab": {}
      },
      "source": [
        "def getImageFromDir(basePath=None, filename=None, className=None):\n",
        "    name, ext = filename.split(\".\")\n",
        "    dirContents = os.listdir(basePath)\n",
        "    for f in dirContents:\n",
        "        maskName, maskExtension = f.split('.')\n",
        "        #print(\"Has className: \", f, \" \" , className, \" \", className in f)\n",
        "        if f.startswith(name) and className in f:\n",
        "            #print(os.path.join(basePath, f))\n",
        "            return os.path.join(basePath, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0nJZtNoE02X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getExif(image=None, key=None):\n",
        "    \"\"\"\n",
        "    Returns a tuple of exif key and exif value\n",
        "    \"\"\"\n",
        "    for (k, v) in PIL.ExifTags.TAGS.items():\n",
        "        if v.lower() == key:\n",
        "            #print(v.lower(), \" \", key)\n",
        "            if image._getexif():\n",
        "                return (k, image._getexif()[k])\n",
        "            else:\n",
        "                return (k, 1)\n",
        "    \n",
        "def fixOrientation(image=None, orientation=1):\n",
        "\n",
        "    result = image\n",
        "    #print(orientation)\n",
        "    if orientation == 3 : \n",
        "        result =  image.rotate(180, expand=True)\n",
        "    elif orientation == 6 : \n",
        "        result = image.rotate(270, expand=True)\n",
        "    elif orientation == 8 : \n",
        "        result = image.rotate(90, expand=True)\n",
        "        \n",
        "    return result\n",
        "\n",
        "def isValidImage(filename=None):\n",
        "    BLACKLIST = [\"kaztest.jpg\"]\n",
        "    VALID_EXTENSIONS = [\"jpg\", \"png\"]\n",
        "    name, extension = filename.split(\".\")\n",
        "    \n",
        "    if extension.lower() not in VALID_EXTENSIONS:\n",
        "        return False\n",
        "    \n",
        "    if filename in BLACKLIST:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "                        \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBbV9Tora90P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "import numpy as np\n",
        "\n",
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uE2h-mZc3MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class CocoConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 80\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "cocoConfig = CocoConfig()\n",
        "#cocoConfig.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJNOAQTYDgu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coco Inference Config\n",
        "\n",
        "class InferenceCocoConfig(CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "\n",
        "inferenceCocoConfig = InferenceCocoConfig()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25S69brw8Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Run inference on images \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "from PIL import Image\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=inferenceCocoConfig,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = WEIGHTS_FILE\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "    \n",
        "    \n",
        "RESULTS = []\n",
        "\n",
        "for imageFilename in os.listdir(imageFilesBasePath)[20:30]:\n",
        "    if not isValidImage(imageFilename):\n",
        "        continue\n",
        "    \n",
        "    imagePath = os.path.join(imageFilesBasePath, imageFilename)\n",
        "    maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")\n",
        "\n",
        "    if not maskPath:\n",
        "        continue\n",
        "    \n",
        "    _image = skimage.io.imread(imagePath)    \n",
        "    _resizeResult = utils.resize_image(_image, max_dim=1024)\n",
        "    _scale = _resizeResult[2]\n",
        "    _padding = _resizeResult[3]\n",
        "    _crop = _resizeResult[4]\n",
        "    imageSrc = _resizeResult[0]\n",
        "    #imageSrc = utils.resize_image(Image.open(imagePath),max_dim=1024)\n",
        "    _maskSrc = skimage.io.imread(maskPath)  #Image.open(maskPath)\n",
        "    \n",
        "    print(_maskSrc.shape)\n",
        "    print(_image.shape)\n",
        "    \n",
        "    _maskTmp = np.expand_dims(_maskSrc, axis=2)\n",
        "    _maskTmp2 = np.tile(_maskTmp, 3)\n",
        "    #_maskTmp = np.tile(_maskSrc, 3)\n",
        "    print (_maskTmp2.shape)\n",
        "    \n",
        "    print(\"####\")\n",
        "    #print(_image.shape)\n",
        "    #print(_maskSrc.shape)\n",
        "    print(_scale, _padding, _crop)\n",
        "    print(_maskSrc)\n",
        "    maskSrc = utils.resize_mask(_maskTmp2, _scale, _padding, _crop)\n",
        "    print(maskSrc.shape)\n",
        "\n",
        "    #orientation = getExif(imageSrc, \"orientation\")\n",
        "    #imageOrientated = fixOrientation(imageSrc, orientation[1])\n",
        "    image = Image.fromarray(imageSrc)\n",
        "    maskImage = Image.fromarray(maskSrc)\n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = image.split()\n",
        "    channelsMask = maskImage.split()\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], channelsMask[0])\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "        \n",
        "    imageArray = numpy.array(imageSrc)\n",
        "\n",
        "    \n",
        "    #plt.figure(figsize=(8, 6))\n",
        "    #plt.title(imagePath.split(\"/\").pop())\n",
        "    #plt.imshow(newImage)\n",
        "    \n",
        "    result = model.detect([imageArray], verbose=1)[0]\n",
        "    RESULTS.append(result)\n",
        "    splash = color_splash(imageArray, result[\"masks\"])\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(result[\"class_ids\"])\n",
        "    plt.imshow(splash)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U35sKd8mUUnv",
        "colab_type": "code",
        "outputId": "35858338-664c-4d79-8f1b-189427345258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "# Macbeth Config\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class MacbethConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"macbeth\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = MacbethConfig()\n",
        "config.display()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  128\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  128\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [128 128   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           macbeth\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPM_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           32\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtBuVhcbQckU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def my_resize_image(image, min_dim=None, max_dim=None, min_scale=None, mode=\"square\"):\n",
        "    \"\"\"Resizes an image keeping the aspect ratio unchanged.\n",
        "\n",
        "    min_dim: if provided, resizes the image such that it's smaller\n",
        "        dimension == min_dim\n",
        "    max_dim: if provided, ensures that the image longest side doesn't\n",
        "        exceed this value.\n",
        "    min_scale: if provided, ensure that the image is scaled up by at least\n",
        "        this percent even if min_dim doesn't require it.\n",
        "    mode: Resizing mode.\n",
        "        none: No resizing. Return the image unchanged.\n",
        "        square: Resize and pad with zeros to get a square image\n",
        "            of size [max_dim, max_dim].\n",
        "        pad64: Pads width and height with zeros to make them multiples of 64.\n",
        "               If min_dim or min_scale are provided, it scales the image up\n",
        "               before padding. max_dim is ignored in this mode.\n",
        "               The multiple of 64 is needed to ensure smooth scaling of feature\n",
        "               maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
        "        crop: Picks random crops from the image. First, scales the image based\n",
        "              on min_dim and min_scale, then picks a random crop of\n",
        "              size min_dim x min_dim. Can be used in training only.\n",
        "              max_dim is not used in this mode.\n",
        "\n",
        "    Returns:\n",
        "    image: the resized image\n",
        "    window: (y1, x1, y2, x2). If max_dim is provided, padding might\n",
        "        be inserted in the returned image. If so, this window is the\n",
        "        coordinates of the image part of the full image (excluding\n",
        "        the padding). The x2, y2 pixels are not included.\n",
        "    scale: The scale factor used to resize the image\n",
        "    padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]\n",
        "    \"\"\"\n",
        "    # Keep track of image dtype and return results in the same dtype\n",
        "    image_dtype = image.dtype\n",
        "    # Default window (y1, x1, y2, x2) and default scale == 1.\n",
        "    h, w = image.shape[:2]\n",
        "    window = (0, 0, h, w)\n",
        "    scale = 1\n",
        "    padding = [(0, 0), (0, 0), (0, 0)]\n",
        "    crop = None\n",
        "\n",
        "    if mode == \"none\":\n",
        "        return image, window, scale, padding, crop\n",
        "\n",
        "    # Scale?\n",
        "    if min_dim:\n",
        "        # Scale up but not down\n",
        "        scale = max(1, min_dim / min(h, w))\n",
        "    if min_scale and scale < min_scale:\n",
        "        scale = min_scale\n",
        "\n",
        "    # Does it exceed max dim?\n",
        "    if max_dim and mode == \"square\":\n",
        "        image_max = max(h, w)\n",
        "        if round(image_max * scale) > max_dim:\n",
        "            scale = max_dim / image_max\n",
        "\n",
        "    # Resize image using bilinear interpolation\n",
        "    if scale != 1:\n",
        "        image = utils.resize(image, (round(h * scale), round(w * scale)),\n",
        "                       preserve_range=True)\n",
        "\n",
        "    # Need padding or cropping?\n",
        "    if mode == \"square\":\n",
        "        # Get new height and width\n",
        "        h, w = image.shape[:2]\n",
        "        top_pad = (max_dim - h) // 2\n",
        "        bottom_pad = max_dim - h - top_pad\n",
        "        left_pad = (max_dim - w) // 2\n",
        "        right_pad = max_dim - w - left_pad\n",
        "        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "        window = (top_pad, left_pad, h + top_pad, w + left_pad)\n",
        "    elif mode == \"pad64\":\n",
        "        h, w = image.shape[:2]\n",
        "        # Both sides must be divisible by 64\n",
        "        assert min_dim % 64 == 0, \"Minimum dimension must be a multiple of 64\"\n",
        "        # Height\n",
        "        if h % 64 > 0:\n",
        "            max_h = h - (h % 64) + 64\n",
        "            top_pad = (max_h - h) // 2\n",
        "            bottom_pad = max_h - h - top_pad\n",
        "        else:\n",
        "            top_pad = bottom_pad = 0\n",
        "        # Width\n",
        "        if w % 64 > 0:\n",
        "            max_w = w - (w % 64) + 64\n",
        "            left_pad = (max_w - w) // 2\n",
        "            right_pad = max_w - w - left_pad\n",
        "        else:\n",
        "            left_pad = right_pad = 0\n",
        "        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "        window = (top_pad, left_pad, h + top_pad, w + left_pad)\n",
        "    elif mode == \"crop\":\n",
        "        # Pick a random crop\n",
        "        h, w = image.shape[:2]\n",
        "        y = random.randint(0, (h - min_dim))\n",
        "        x = random.randint(0, (w - min_dim))\n",
        "        crop = (y, x, min_dim, min_dim)\n",
        "        image = image[y:y + min_dim, x:x + min_dim]\n",
        "        window = (0, 0, min_dim, min_dim)\n",
        "    else:\n",
        "        raise Exception(\"Mode {} not supported\".format(mode))\n",
        "    return image.astype(image_dtype), window, scale, padding, crop\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCSAPTkbX5mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(BASEDIR)\n",
        "\n",
        "# URL from which to download the latest COCO trained weights\n",
        "COCO_MODEL_URL = \"https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "#imageFilesBasePath = \"/root/data/mine/machineLearning/macbethIdentify/data/data/img\"\n",
        "maskFilesBasePath = maskFilesBasePath\n",
        "\n",
        "\n",
        "# Dataset\n",
        "class MacbethDataset(utils.Dataset):\n",
        "    #def __init__(self):\n",
        "    #    super().__init__()\n",
        "    #    self.imageResizeParams = {}\n",
        "    \n",
        "    def load_macbeths(self, dataset_dir, subset):\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"macbeth\", 1, \"macbeth\")\n",
        "        \n",
        "        i = 0\n",
        "\n",
        "        _annotationsFile = json.load(open(JSON_FILE))\n",
        "        annotations = [x for x in list(_annotationsFile.values()) if x['regions'] ]\n",
        "            \n",
        "        print(annotations)\n",
        "        \n",
        "        for a in annotations:\n",
        "            \n",
        "            polygons = []\n",
        "            for region in a['regions'].values():\n",
        "                #print(region) #[\"shape_attributes\"]\n",
        "                #print(region['shape_attributes'])\n",
        "                polygons.append(region['shape_attributes'])             \n",
        "\n",
        "            #print(polygons)\n",
        "            \n",
        "            imagePath = os.path.join(imageFilesBasePath, a[\"filename\"])\n",
        "\n",
        "            if not os.path.isfile(imagePath):\n",
        "                continue\n",
        "                \n",
        "            _image = skimage.io.imread(imagePath)\n",
        "            height, width = _image.shape[:2]\n",
        "                \n",
        "            #print(os.path.isfile(imagePath))            \n",
        "            #print(height, width)\n",
        "            \n",
        "            self.add_image(\n",
        "                \"macbeth\",\n",
        "                image_id=a[\"filename\"],\n",
        "                path=imagePath,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                polygons=polygons\n",
        "            )\n",
        "            #self._image_ids.append(i)\n",
        "            #i += 1\n",
        "            \n",
        "        \"\"\"    \n",
        "        for imageFilename in os.listdir(dataset_dir)[:0]:\n",
        "            if not isValidImage(imageFilename):\n",
        "                continue\n",
        "    \n",
        "            imagePath = os.path.join(dataset_dir, imageFilename)\n",
        "            maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")  \n",
        "            \n",
        "            if not maskPath:\n",
        "                continue\n",
        "                \n",
        "            if not os.path.isfile(imagePath):\n",
        "                continue\n",
        "                \n",
        "            if not os.path.isfile(maskPath):\n",
        "                continue\n",
        "                \n",
        "\n",
        "            \n",
        "            _image = skimage.io.imread(imagePath)\n",
        "            #print(_image.shape)\n",
        "            _resizeResults = my_resize_image(_image, max_dim=1024)\n",
        "            #print(\"_resizeResults: \", _resizeResults)\n",
        "            image = _resizeResults[0]\n",
        "            _scale = _resizeResults[2]\n",
        "            _padding = _resizeResults[3]\n",
        "            _crop = _resizeResults[4]\n",
        "\n",
        "            #print(\"_scale: \", _scale, \"_padding: \", _padding)\n",
        "            self.imageResizeParams[i] = [_scale, _padding, _crop]\n",
        "            height, width = image.shape[:2]\n",
        "            #print(width, height)\n",
        "            #print(\"Adding: \", imagePath)\n",
        "            #print(\"Adding: \", maskPath)\n",
        "            self.add_image(\n",
        "                \"macbeth\",\n",
        "                image_id=i,\n",
        "                path=imagePath,\n",
        "                width=width,\n",
        "                height=height\n",
        "            )\n",
        "            self._image_ids.append(i)\n",
        "            i += 1\n",
        "            \"\"\"\n",
        "        \n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        print(\"load image\")\n",
        "        print(type(self.image_info))\n",
        "        print(self.image_info[image_id])\n",
        "        print(self.image_info[image_id]['path'])\n",
        "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "            \n",
        "        return image\n",
        "    \n",
        "    \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        \n",
        "        print(\"load_mask\")\n",
        "        \n",
        "        # If not a balloon dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        print(image_info)\n",
        "        if image_info[\"source\"] != \"macbeth\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        print(info)\n",
        "        print(info[\"height\"], \" - \", info[\"width\"], \" : \", len(info[\"polygons\"]))\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        \n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            print(p['all_points_y'])\n",
        "            print(p['all_points_x'])\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            print(i, \": \", rr, \"-\", cc)\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        print(mask.shape)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(numpy.tile(mask, 3))\n",
        "    \n",
        "        print(\"TEST\")\n",
        "        print(mask.shape[-1])\n",
        "        return mask\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        #return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)    \n",
        "        \n",
        "    \"\"\"    \n",
        "    def load_maskx(self, image_id):\n",
        "        \n",
        "        maskPath = getImageFromDir(maskFilesBasePath, self.image_info[image_id][\"path\"].split(\"/\").pop(), \"macbeth\")  \n",
        "        #print(maskPath)\n",
        "        assert os.path.isfile(maskPath)\n",
        "\n",
        "        # I think this is width, height, number of instances\n",
        "        #mask = np.zeros([self.image_info[image_id][\"width\"], self.image_info[image_id][\"height\"], 1], dtype=np.uint8)\n",
        "        _maskSrc = skimage.io.imread(maskPath)\n",
        "        \n",
        "        print(\"_maskSrc.shape: \", _maskSrc.shape)\n",
        "        _maskTmp = np.expand_dims(_maskSrc, axis=2)\n",
        "        print(\"_maskTmp.shape: \", _maskTmp.shape)\n",
        "        #_maskTmp2 = np.tile(_maskTmp, 3)\n",
        "        #_maskTmp = np.tile(_maskSrc, 3)\n",
        "        #print (_maskTmp2.shape)\n",
        "\n",
        "        _scale = self.imageResizeParams[image_id][0]\n",
        "        _padding = self.imageResizeParams[image_id][1]\n",
        "        print(\"_scale: \", _scale, \"_padding: \", _padding)\n",
        "        \n",
        "        maskSrc = utils.resize_mask(_maskTmp, _scale, _padding)\n",
        "        #maskArray = numpy.array(maskSrc)\n",
        "        \n",
        "        #print(\"tile: \", _maskTmp2.shape)\n",
        "        #print(\"msh:\", mask.shape)\n",
        "        print(\"maskSrc.shape:\", maskSrc.shape)\n",
        "        \n",
        "        #return [1,_maskTmp]\n",
        "        mask = np.zeros([self.image_info[image_id][\"width\"], self.image_info[image_id][\"height\"], 1], dtype=np.uint8)\n",
        "        print([self.image_info[image_id][\"width\"], self.image_info[image_id][\"height\"]])\n",
        "        print(\"mask.shape: \", mask.shape)\n",
        "        return mask\n",
        "        \"\"\"\n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"macbeth\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcb-VNdcyyYW",
        "colab_type": "code",
        "outputId": "e2cf254c-6683-446a-b7d2-9e59d45ef538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(BASEDIR)\n",
        "print(maskFilesBasePath)\n",
        "print(imageFilesBasePath)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/mask_images\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPQcbYWaPUl",
        "colab_type": "code",
        "outputId": "d40353ac-fe20-4333-f5d2-e4fe5e652f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# test stuff\n",
        "imgPath = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00135.jpg\"\n",
        "maskPath = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/mask_images/penn_jillette_00135_class_macbeth.png\"\n",
        "#mask = np.zeros([1000, 2000, 1], dtype=np.uint8)\n",
        "\n",
        "#test = MacbethDataset()\n",
        "#test.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "#array = test.load_image(1)\n",
        "\n",
        "#print(type(array))\n",
        "#print(type(mask))\n",
        "\n",
        "#print(array.shape)\n",
        "\n",
        "image = skimage.io.imread(imgPath)\n",
        "_mask = skimage.io.imread(maskPath)\n",
        "\n",
        "mask = numpy.expand_dims(_mask, axis=2)\n",
        "\n",
        "print(image.shape)\n",
        "print(_mask.shape)\n",
        "print(mask.shape)\n",
        "\n",
        "resized_image = utils.resize_image(image, max_dim=1024)\n",
        "resized_mask = utils.resize_mask(mask, resized_image[2], resized_image[3])\n",
        "\n",
        "print(resized_image[0].shape)\n",
        "print(resized_mask.shape)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1869, 1400, 3)\n",
            "(1869, 1400)\n",
            "(1869, 1400, 1)\n",
            "(1024, 1024, 3)\n",
            "(1024, 1024, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1K36Et6c6BI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "a88801d6-5852-46cf-8589-93096e268840"
      },
      "source": [
        "#\n",
        "# Visualise image and matte overlays are working through the dataset class\n",
        "#\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "#import importlib\n",
        "#importlib.reload(mrcnn.utils)\n",
        "\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "print(dir(dataset_train))\n",
        "\n",
        "print(dataset_train._image_ids)\n",
        "print(dataset_train.image_info)\n",
        "print(type(dataset_train.image_info))\n",
        "\n",
        "images = len(dataset_train.image_info)\n",
        "\n",
        "for i in range(images)[:5]:\n",
        "\n",
        "    _img = dataset_train.load_image(i)\n",
        "    _mask - dataset_train.load_mask(i)\n",
        "    \n",
        "    continue\n",
        "    print(_img.shape)\n",
        "    print(_mask.shape)\n",
        "    # Test overlays of masks\n",
        "    channels = _img.split()\n",
        "    #print(channels)\n",
        "    #print(mask)\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], _mask)\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "        \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(newImage)\n",
        "    \n",
        "    \"\"\"\n",
        "    continue\n",
        "    #_resizeResults = my_resize_image(_img, max_dim=1024)\n",
        "    img = Image.fromarray(_resizeResults[0])\n",
        "    \n",
        "    \n",
        "    #tst = dataset_train.load_image(f)\n",
        "    #print(tst.dtype)\n",
        "    #img2 = utils.resize_image(img, max_dim=1024)\n",
        "    \n",
        "    mask = Image.fromarray(dataset_train.load_mask(f)[1])\n",
        "    \n",
        "    #print(\"img.size: \", img.size)\n",
        "    #print(\"width: \", mask.width)\n",
        "    #print(\"height:\", mask.height)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    #plt.title(\"banana\")\n",
        "    plt.imshow(mask)\n",
        "    \n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = img.split()\n",
        "    #print(channels)\n",
        "    #print(mask)\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], mask)\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(\"banana\")\n",
        "    plt.imshow(newImage)\n",
        "\"\"\"    \n",
        "    \n"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'fileref': '', 'size': 23232323, 'filename': 'jeff_kolitch_00097-mos.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [335, 405, 398, 331], 'all_points_y': [519, 518, 419, 422]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'penn_jillette_00106.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [369, 608, 608, 608, 369], 'all_points_y': [769, 769, 685, 601, 601]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'kaztest.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [301, 391, 448, 358], 'all_points_y': [362, 444, 382, 300]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'megan_rapinoe_00023.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [216, 366, 358, 208], 'all_points_y': [593, 581, 478, 490]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'megan_rapinoe_mg_0013.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [253, 490, 493, 492, 243], 'all_points_y': [804, 799, 735, 668, 674]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'megan_rapinoe_mg_0100.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [380, 457, 534, 540, 378], 'all_points_y': [900, 904, 909, 812, 804]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'mg_0006.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [473, 700, 708, 486], 'all_points_y': [818, 826, 663, 658]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'mg_0008.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [266, 260, 367, 371], 'all_points_y': [635, 786, 789, 639]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'p04.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [42, 49, 274, 281], 'all_points_y': [25, 187, 185, 26]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'penn_jillette_00135.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [526, 851, 841, 515], 'all_points_y': [935, 921, 692, 707]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'robert_benmosche_00011.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [491, 497, 760, 757], 'all_points_y': [438, 619, 617, 436]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'rt2012_xboard_00012-mos.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [413, 408, 504, 509], 'all_points_y': [323, 389, 398, 332]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'sg11.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [313, 314, 452, 452], 'all_points_y': [307, 403, 404, 305]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'sg13.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [273, 269, 425, 428], 'all_points_y': [431, 540, 547, 438]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'sg8.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [420, 423, 543, 540], 'all_points_y': [481, 563, 561, 477]}}}}, {'fileref': '', 'size': 23232323, 'filename': 't-7797r.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [49, 52, 184, 183], 'all_points_y': [172, 262, 262, 169]}}}}, {'fileref': '', 'size': 23232323, 'filename': '2_associates_00002.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [349, 358, 846, 835], 'all_points_y': [1147, 1491, 1475, 1135]}}}}, {'fileref': '', 'size': 23232323, 'filename': '2013_rt_cover_brian_rogers_00001-mos.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [233, 228, 342, 346], 'all_points_y': [362, 434, 432, 360]}}}}, {'fileref': '', 'size': 23232323, 'filename': '6associates_bluetest.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [930, 1163, 1163, 1047, 930], 'all_points_y': [1843, 1843, 1681, 1681, 1681]}}}}, {'fileref': '', 'size': 23232323, 'filename': '7.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [397, 482, 470, 386], 'all_points_y': [684, 693, 811, 800]}}}}, {'fileref': '', 'size': 23232323, 'filename': '8D5U5533_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [66, 348, 380, 64], 'all_points_y': [497, 492, 680, 687]}}}}, {'fileref': '', 'size': 23232323, 'filename': '8D5U5545_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [107, 432, 416, 86], 'all_points_y': [260, 288, 549, 520]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'ARMAFC.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [197, 182, 1050, 1053], 'all_points_y': [142, 744, 757, 157]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'bob_amsterdam_00052.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [446, 592, 598, 454], 'all_points_y': [484, 477, 684, 689]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'bobby_flay_00217.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [682, 776, 782, 686], 'all_points_y': [529, 519, 587, 596]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'bobby_flay_00254.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [900, 1027, 1028, 902], 'all_points_y': [485, 483, 572, 574]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'brendan_haircut_00001.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [306, 766, 767, 307], 'all_points_y': [921, 918, 1234, 1241]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'bts1.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1041, 1440, 1367, 862], 'all_points_y': [387, 654, 961, 653]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'catherine_mary_stewart_00074.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [637, 796, 792, 632], 'all_points_y': [660, 668, 778, 770]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'catherine_mary_stewart_00331-mos.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [410, 372, 236, 261], 'all_points_y': [726, 637, 721, 800]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'catherine_mary_stewart_00461.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [694, 696, 907, 905], 'all_points_y': [581, 726, 722, 574]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'deb1.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [142, 140, 281, 276], 'all_points_y': [153, 243, 232, 139]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'girl-with-colorchecker.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [102, 446, 449, 106], 'all_points_y': [347, 344, 579, 583]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'img_0172.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1069, 946, 1235, 1400], 'all_points_y': [380, 664, 844, 453]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_0319_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [400, 403, 527, 519], 'all_points_y': [474, 558, 556, 475]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_0341_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [696, 670, 760, 786], 'all_points_y': [191, 247, 268, 208]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_0475_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [761, 841, 719, 652], 'all_points_y': [353, 411, 522, 449]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_0481_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [105, 102, 261, 246], 'all_points_y': [427, 509, 507, 433]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_0750_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [734, 719, 814, 826], 'all_points_y': [379, 437, 464, 403]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1309 2.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [310, 1315, 2877, 1809], 'all_points_y': [1832, 2945, 1420, 418]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1310.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1712, 2526, 1064, 286], 'all_points_y': [2996, 1992, 874, 1885]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1311.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [863, 987, 1891, 1731], 'all_points_y': [2125, 2746, 2517, 1908]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1312.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1798, 2314, 1220, 686], 'all_points_y': [1181, 1957, 2699, 1928]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1313.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1339, 1929, 2324, 1794], 'all_points_y': [1057, 1851, 1579, 873]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1314.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1544, 1184, 3882, 3533], 'all_points_y': [550, 1722, 2008, 791]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1315.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1478, 1949, 2350, 2103], 'all_points_y': [984, 2806, 2249, 825]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1316.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1604, 2187, 2375, 1991], 'all_points_y': [284, 105, 1407, 1796]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1317.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [471, 967, 1596, 1233], 'all_points_y': [738, 1941, 1630, 520]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1318.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1248, 2147, 2114, 1273], 'all_points_y': [788, 803, 2037, 2033]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1319.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1961, 1905, 2514, 2481], 'all_points_y': [1554, 2039, 2127, 1597]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1320.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1250, 1748, 1782, 1219], 'all_points_y': [1518, 1514, 2150, 2146]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1321.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1345, 2004, 2187, 1308], 'all_points_y': [1047, 982, 1402, 1445]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1322.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [813, 1237, 2775, 1923], 'all_points_y': [537, 1724, 1236, 176]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1323.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1009, 1162, 1868, 1650], 'all_points_y': [1935, 2268, 2129, 1839]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1324.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1348, 1449, 1948, 1814], 'all_points_y': [2093, 2345, 2260, 2020]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1325.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1807, 1839, 2185, 2129], 'all_points_y': [1833, 1926, 1903, 1816]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1326.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1285, 1367, 1989, 1862], 'all_points_y': [1565, 1740, 1662, 1515]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1327.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [800, 842, 1175, 1115], 'all_points_y': [1165, 1228, 1208, 1157]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1328.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1928, 1899, 2351, 2388], 'all_points_y': [1331, 1443, 1622, 1407]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1329.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1749, 1795, 2134, 2432, 2322], 'all_points_y': [2382, 2719, 2727, 2665, 2264]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1330.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [2131, 1574, 2321, 2834], 'all_points_y': [748, 1868, 2260, 1174]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1331.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1470, 776, 2149, 2754], 'all_points_y': [1756, 2396, 3268, 2342]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1332.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1732, 2892, 1549, 230], 'all_points_y': [1446, 1863, 3509, 2430]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1333.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [693, 2379, 1981, 514], 'all_points_y': [2795, 2552, 343, 716]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1335.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [924, 821, 2372, 2161], 'all_points_y': [1896, 2653, 2607, 1867]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1336.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1070, 1123, 2073, 2018], 'all_points_y': [1415, 2097, 2025, 1356]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1337.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [885, 955, 1956, 2007], 'all_points_y': [1522, 2178, 2201, 1513]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1338.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [922, 1124, 1803, 1674], 'all_points_y': [2006, 2649, 3062, 2168]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1339.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [804, 1194, 2103, 1800], 'all_points_y': [690, 1530, 1750, 572]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1340.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1557, 1541, 2056, 2082], 'all_points_y': [1649, 2307, 2080, 1504]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1341.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [946, 1001, 2205, 2150], 'all_points_y': [1400, 2249, 2201, 1248]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1342.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1148, 1248, 2390, 2396], 'all_points_y': [1336, 2329, 2853, 1390]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1343.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1072, 2223, 1890, 812], 'all_points_y': [2019, 2016, 3423, 2999]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1344.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1142, 1846, 2138, 1433], 'all_points_y': [1485, 1276, 2313, 2467]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1346.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [311, 739, 2185, 2211], 'all_points_y': [1097, 1926, 1934, 903]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1347.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1657, 1235, 2330, 2689], 'all_points_y': [1131, 2643, 2914, 1402]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1348.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [855, 2288, 2152, 861], 'all_points_y': [1415, 1469, 3438, 3253]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1349.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1842, 2371, 2348, 1831], 'all_points_y': [1534, 1556, 2437, 2322]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1334.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [511, 1068, 2923, 2073], 'all_points_y': [882, 1720, 1036, 532]}}}}, {'fileref': '', 'size': 23232323, 'filename': '8D5U5595_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [265, 340, 338, 265], 'all_points_y': [603, 607, 657, 654]}}}}, {'fileref': '', 'size': 23232323, 'filename': '8D5U5611_orig.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [82, 222, 238, 98], 'all_points_y': [313, 289, 391, 421]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'IMG_1345.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [960, 1384, 2146, 1943], 'all_points_y': [1508, 2828, 2423, 1170]}}}}, {'fileref': '', 'size': 23232323, 'filename': 'mcc3-t.jpg', 'base64_img_data': '', 'file_attributes': {}, 'regions': {'0': {'shape_attributes': {'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1, 143, 143, 143, 2], 'all_points_y': [99, 99, 50, 2, 1]}}}}]\n",
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_image_ids', 'add_class', 'add_image', 'class_info', 'get_source_class_id', 'image_ids', 'image_info', 'image_reference', 'load_image', 'load_macbeths', 'load_mask', 'map_source_class_id', 'prepare', 'source_class_ids', 'source_image_link']\n",
            "[]\n",
            "[{'id': 'jeff_kolitch_00097-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/jeff_kolitch_00097-mos.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [335, 405, 398, 331], 'all_points_y': [519, 518, 419, 422]}]}, {'id': 'penn_jillette_00106.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00106.jpg', 'width': 1400, 'height': 1869, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [369, 608, 608, 608, 369], 'all_points_y': [769, 769, 685, 601, 601]}]}, {'id': 'kaztest.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/kaztest.jpg', 'width': 720, 'height': 961, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [301, 391, 448, 358], 'all_points_y': [362, 444, 382, 300]}]}, {'id': 'megan_rapinoe_00023.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/megan_rapinoe_00023.jpg', 'width': 864, 'height': 1153, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [216, 366, 358, 208], 'all_points_y': [593, 581, 478, 490]}]}, {'id': 'megan_rapinoe_mg_0013.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/megan_rapinoe_mg_0013.jpg', 'width': 864, 'height': 1295, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [253, 490, 493, 492, 243], 'all_points_y': [804, 799, 735, 668, 674]}]}, {'id': 'megan_rapinoe_mg_0100.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/megan_rapinoe_mg_0100.jpg', 'width': 1001, 'height': 1500, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [380, 457, 534, 540, 378], 'all_points_y': [900, 904, 909, 812, 804]}]}, {'id': 'mg_0008.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/mg_0008.jpg', 'width': 1008, 'height': 1512, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [266, 260, 367, 371], 'all_points_y': [635, 786, 789, 639]}]}, {'id': 'p04.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/p04.jpg', 'width': 320, 'height': 240, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [42, 49, 274, 281], 'all_points_y': [25, 187, 185, 26]}]}, {'id': 'penn_jillette_00135.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00135.jpg', 'width': 1400, 'height': 1869, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [526, 851, 841, 515], 'all_points_y': [935, 921, 692, 707]}]}, {'id': 'robert_benmosche_00011.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/robert_benmosche_00011.jpg', 'width': 1498, 'height': 2000, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [491, 497, 760, 757], 'all_points_y': [438, 619, 617, 436]}]}, {'id': 'rt2012_xboard_00012-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/rt2012_xboard_00012-mos.jpg', 'width': 961, 'height': 720, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [413, 408, 504, 509], 'all_points_y': [323, 389, 398, 332]}]}, {'id': 'sg11.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/sg11.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [313, 314, 452, 452], 'all_points_y': [307, 403, 404, 305]}]}, {'id': 'sg13.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/sg13.jpg', 'width': 864, 'height': 1295, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [273, 269, 425, 428], 'all_points_y': [431, 540, 547, 438]}]}, {'id': 'sg8.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/sg8.jpg', 'width': 864, 'height': 1154, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [420, 423, 543, 540], 'all_points_y': [481, 563, 561, 477]}]}, {'id': 't-7797r.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/t-7797r.jpg', 'width': 240, 'height': 320, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [49, 52, 184, 183], 'all_points_y': [172, 262, 262, 169]}]}, {'id': '2_associates_00002.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/2_associates_00002.jpg', 'width': 2000, 'height': 2670, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [349, 358, 846, 835], 'all_points_y': [1147, 1491, 1475, 1135]}]}, {'id': '2013_rt_cover_brian_rogers_00001-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/2013_rt_cover_brian_rogers_00001-mos.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [233, 228, 342, 346], 'all_points_y': [362, 434, 432, 360]}]}, {'id': '6associates_bluetest.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/6associates_bluetest.jpg', 'width': 2000, 'height': 2671, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [930, 1163, 1163, 1047, 930], 'all_points_y': [1843, 1843, 1681, 1681, 1681]}]}, {'id': '7.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/7.jpg', 'width': 864, 'height': 1296, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [397, 482, 470, 386], 'all_points_y': [684, 693, 811, 800]}]}, {'id': '8D5U5533_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/8D5U5533_orig.jpg', 'width': 541, 'height': 813, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [66, 348, 380, 64], 'all_points_y': [497, 492, 680, 687]}]}, {'id': '8D5U5545_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/8D5U5545_orig.jpg', 'width': 813, 'height': 541, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [107, 432, 416, 86], 'all_points_y': [260, 288, 549, 520]}]}, {'id': 'ARMAFC.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/ARMAFC.jpg', 'width': 1300, 'height': 955, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [197, 182, 1050, 1053], 'all_points_y': [142, 744, 757, 157]}]}, {'id': 'bobby_flay_00217.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/bobby_flay_00217.jpg', 'width': 1538, 'height': 1152, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [682, 776, 782, 686], 'all_points_y': [529, 519, 587, 596]}]}, {'id': 'bobby_flay_00254.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/bobby_flay_00254.jpg', 'width': 1538, 'height': 1152, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [900, 1027, 1028, 902], 'all_points_y': [485, 483, 572, 574]}]}, {'id': 'brendan_haircut_00001.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/brendan_haircut_00001.jpg', 'width': 1152, 'height': 1538, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [306, 766, 767, 307], 'all_points_y': [921, 918, 1234, 1241]}]}, {'id': 'bts1.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/bts1.jpg', 'width': 1440, 'height': 1080, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1041, 1440, 1367, 862], 'all_points_y': [387, 654, 961, 653]}]}, {'id': 'catherine_mary_stewart_00074.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/catherine_mary_stewart_00074.jpg', 'width': 970, 'height': 1296, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [637, 796, 792, 632], 'all_points_y': [660, 668, 778, 770]}]}, {'id': 'catherine_mary_stewart_00331-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/catherine_mary_stewart_00331-mos.jpg', 'width': 1022, 'height': 766, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [410, 372, 236, 261], 'all_points_y': [726, 637, 721, 800]}]}, {'id': 'catherine_mary_stewart_00461.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/catherine_mary_stewart_00461.jpg', 'width': 1123, 'height': 1500, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [694, 696, 907, 905], 'all_points_y': [581, 726, 722, 574]}]}, {'id': 'deb1.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/deb1.jpg', 'width': 312, 'height': 371, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [142, 140, 281, 276], 'all_points_y': [153, 243, 232, 139]}]}, {'id': 'girl-with-colorchecker.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/girl-with-colorchecker.jpg', 'width': 800, 'height': 701, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [102, 446, 449, 106], 'all_points_y': [347, 344, 579, 583]}]}, {'id': 'img_0172.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/img_0172.jpg', 'width': 1440, 'height': 1080, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1069, 946, 1235, 1400], 'all_points_y': [380, 664, 844, 453]}]}, {'id': 'IMG_0319_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_0319_orig.jpg', 'width': 584, 'height': 877, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [400, 403, 527, 519], 'all_points_y': [474, 558, 556, 475]}]}, {'id': 'IMG_0341_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_0341_orig.jpg', 'width': 874, 'height': 583, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [696, 670, 760, 786], 'all_points_y': [191, 247, 268, 208]}]}, {'id': 'IMG_0481_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_0481_orig.jpg', 'width': 874, 'height': 583, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [105, 102, 261, 246], 'all_points_y': [427, 509, 507, 433]}]}, {'id': 'IMG_0750_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_0750_orig.jpg', 'width': 874, 'height': 583, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [734, 719, 814, 826], 'all_points_y': [379, 437, 464, 403]}]}, {'id': 'IMG_1309 2.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1309 2.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [310, 1315, 2877, 1809], 'all_points_y': [1832, 2945, 1420, 418]}]}, {'id': 'IMG_1310.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1310.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1712, 2526, 1064, 286], 'all_points_y': [2996, 1992, 874, 1885]}]}, {'id': 'IMG_1311.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1311.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [863, 987, 1891, 1731], 'all_points_y': [2125, 2746, 2517, 1908]}]}, {'id': 'IMG_1312.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1312.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1798, 2314, 1220, 686], 'all_points_y': [1181, 1957, 2699, 1928]}]}, {'id': 'IMG_1313.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1313.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1339, 1929, 2324, 1794], 'all_points_y': [1057, 1851, 1579, 873]}]}, {'id': 'IMG_1314.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1314.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1544, 1184, 3882, 3533], 'all_points_y': [550, 1722, 2008, 791]}]}, {'id': 'IMG_1315.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1315.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1478, 1949, 2350, 2103], 'all_points_y': [984, 2806, 2249, 825]}]}, {'id': 'IMG_1316.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1316.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1604, 2187, 2375, 1991], 'all_points_y': [284, 105, 1407, 1796]}]}, {'id': 'IMG_1317.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1317.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [471, 967, 1596, 1233], 'all_points_y': [738, 1941, 1630, 520]}]}, {'id': 'IMG_1318.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1318.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1248, 2147, 2114, 1273], 'all_points_y': [788, 803, 2037, 2033]}]}, {'id': 'IMG_1319.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1319.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1961, 1905, 2514, 2481], 'all_points_y': [1554, 2039, 2127, 1597]}]}, {'id': 'IMG_1320.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1320.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1250, 1748, 1782, 1219], 'all_points_y': [1518, 1514, 2150, 2146]}]}, {'id': 'IMG_1321.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1321.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1345, 2004, 2187, 1308], 'all_points_y': [1047, 982, 1402, 1445]}]}, {'id': 'IMG_1322.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1322.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [813, 1237, 2775, 1923], 'all_points_y': [537, 1724, 1236, 176]}]}, {'id': 'IMG_1323.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1323.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1009, 1162, 1868, 1650], 'all_points_y': [1935, 2268, 2129, 1839]}]}, {'id': 'IMG_1324.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1324.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1348, 1449, 1948, 1814], 'all_points_y': [2093, 2345, 2260, 2020]}]}, {'id': 'IMG_1325.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1325.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1807, 1839, 2185, 2129], 'all_points_y': [1833, 1926, 1903, 1816]}]}, {'id': 'IMG_1326.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1326.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1285, 1367, 1989, 1862], 'all_points_y': [1565, 1740, 1662, 1515]}]}, {'id': 'IMG_1327.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1327.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [800, 842, 1175, 1115], 'all_points_y': [1165, 1228, 1208, 1157]}]}, {'id': 'IMG_1328.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1328.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1928, 1899, 2351, 2388], 'all_points_y': [1331, 1443, 1622, 1407]}]}, {'id': 'IMG_1329.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1329.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1749, 1795, 2134, 2432, 2322], 'all_points_y': [2382, 2719, 2727, 2665, 2264]}]}, {'id': 'IMG_1330.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1330.jpg', 'width': 4032, 'height': 3024, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [2131, 1574, 2321, 2834], 'all_points_y': [748, 1868, 2260, 1174]}]}, {'id': 'IMG_1331.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1331.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1470, 776, 2149, 2754], 'all_points_y': [1756, 2396, 3268, 2342]}]}, {'id': 'IMG_1332.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1332.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1732, 2892, 1549, 230], 'all_points_y': [1446, 1863, 3509, 2430]}]}, {'id': 'IMG_1333.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1333.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [693, 2379, 1981, 514], 'all_points_y': [2795, 2552, 343, 716]}]}, {'id': 'IMG_1335.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1335.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [924, 821, 2372, 2161], 'all_points_y': [1896, 2653, 2607, 1867]}]}, {'id': 'IMG_1337.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1337.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [885, 955, 1956, 2007], 'all_points_y': [1522, 2178, 2201, 1513]}]}, {'id': 'IMG_1338.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1338.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [922, 1124, 1803, 1674], 'all_points_y': [2006, 2649, 3062, 2168]}]}, {'id': 'IMG_1339.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1339.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [804, 1194, 2103, 1800], 'all_points_y': [690, 1530, 1750, 572]}]}, {'id': 'IMG_1341.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1341.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [946, 1001, 2205, 2150], 'all_points_y': [1400, 2249, 2201, 1248]}]}, {'id': 'IMG_1342.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1342.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1148, 1248, 2390, 2396], 'all_points_y': [1336, 2329, 2853, 1390]}]}, {'id': 'IMG_1343.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1343.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1072, 2223, 1890, 812], 'all_points_y': [2019, 2016, 3423, 2999]}]}, {'id': 'IMG_1344.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1344.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1142, 1846, 2138, 1433], 'all_points_y': [1485, 1276, 2313, 2467]}]}, {'id': 'IMG_1346.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1346.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [311, 739, 2185, 2211], 'all_points_y': [1097, 1926, 1934, 903]}]}, {'id': 'IMG_1347.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1347.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1657, 1235, 2330, 2689], 'all_points_y': [1131, 2643, 2914, 1402]}]}, {'id': 'IMG_1348.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1348.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [855, 2288, 2152, 861], 'all_points_y': [1415, 1469, 3438, 3253]}]}, {'id': 'IMG_1349.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1349.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1842, 2371, 2348, 1831], 'all_points_y': [1534, 1556, 2437, 2322]}]}, {'id': 'IMG_1334.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1334.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [511, 1068, 2923, 2073], 'all_points_y': [882, 1720, 1036, 532]}]}, {'id': '8D5U5595_orig.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/8D5U5595_orig.jpg', 'width': 544, 'height': 816, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [265, 340, 338, 265], 'all_points_y': [603, 607, 657, 654]}]}, {'id': 'IMG_1345.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/IMG_1345.jpg', 'width': 3024, 'height': 4032, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [960, 1384, 2146, 1943], 'all_points_y': [1508, 2828, 2423, 1170]}]}, {'id': 'mcc3-t.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/mcc3-t.jpg', 'width': 143, 'height': 99, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [1, 143, 143, 143, 2], 'all_points_y': [99, 99, 50, 2, 1]}]}]\n",
            "<class 'list'>\n",
            "load image\n",
            "<class 'list'>\n",
            "{'id': 'jeff_kolitch_00097-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/jeff_kolitch_00097-mos.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [335, 405, 398, 331], 'all_points_y': [519, 518, 419, 422]}]}\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/jeff_kolitch_00097-mos.jpg\n",
            "load_mask\n",
            "{'id': 'jeff_kolitch_00097-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/jeff_kolitch_00097-mos.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [335, 405, 398, 331], 'all_points_y': [519, 518, 419, 422]}]}\n",
            "{'id': 'jeff_kolitch_00097-mos.jpg', 'source': 'macbeth', 'path': '/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/jeff_kolitch_00097-mos.jpg', 'width': 766, 'height': 1022, 'polygons': [{'name': 'polygon', 'region_attributes': {}, 'all_points_x': [335, 405, 398, 331], 'all_points_y': [519, 518, 419, 422]}]}\n",
            "1022  -  766  :  1\n",
            "[519, 518, 419, 422]\n",
            "[335, 405, 398, 331]\n",
            "0 :  [420 420 420 ... 518 518 518] - [376 377 378 ... 402 403 404]\n",
            "(1022, 766, 1)\n",
            "TEST\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-345-342b5ee4a37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0m_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_mask\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1869,1400) (1022,766,1) "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASYAAAFpCAYAAAAxyoVjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk6R2DJOkdgyTpHYMk6R2DJOkdv4fJULXKn8SbsoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX9GlLlfikA",
        "colab_type": "code",
        "outputId": "bf5db0a0-dd99-492d-c329-a09157d98810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "#\n",
        "# Perform Training\n",
        "#\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "print(\"FSFDFDF\")\n",
        "\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "#dataset_val = MacbethDataset()\n",
        "#dataset_val.load_macbeths(\"/root/data/mine/machineLearning/macbethIdentify/data/data/img_val\", \"val\")\n",
        "#dataset_val.prepare()\n",
        "\n",
        "print(\"Training network heads\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "           learning_rate=config.LEARNING_RATE,\n",
        "           epochs=30,\n",
        "           layers='heads')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ab96180e5a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_LOGS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FSFDFDF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacbethDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2463\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2464\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2465\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \"\"\"\n\u001b[1;32m   1761\u001b[0m     assign = state_ops.assign(self._variable, value, use_locking=use_locking,\n\u001b[0;32m-> 1762\u001b[0;31m                               name=name)\n\u001b[0m\u001b[1;32m   1763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    221\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    222\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMIy8eWoiJLN",
        "colab_type": "code",
        "outputId": "ea28761c-0dcb-4ee2-c99c-ebb939ec9489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%cd ~/data//mine/machineLearning/macbethIdentify/data/data/\n",
        "%ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data/mine/machineLearning/macbethIdentify/data/data\n",
            "total 48\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mannottions_json\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mimg\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 04:59 \u001b[01;34mimg_val\u001b[0m/\n",
            "-rwx------ 1 root root    34 Apr 27 03:50 \u001b[01;32mlabel_map.pbtxt\u001b[0m*\n",
            "drwx------ 2 root root 16384 May 26 05:05 \u001b[01;34mmask_images\u001b[0m/\n",
            "-rwx------ 1 root root   127 Apr  9 00:21 \u001b[01;32mtest.txt\u001b[0m*\n",
            "-rwx------ 1 root root  1031 Apr 27 03:50 \u001b[01;32mtrain.txt\u001b[0m*\n",
            "-rwx------ 1 root root   141 Apr  9 00:21 \u001b[01;32mval.txt\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd4KUgaZMLl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}