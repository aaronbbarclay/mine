{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Macbeth_learn_maskrcnn_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbbarclay/mine/blob/master/Macbeth_learn_maskrcnn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zafzl1Ptq2",
        "colab_type": "text"
      },
      "source": [
        "Using mask RCNN to train macbeth detection\n",
        "\n",
        "https://github.com/matterport/Mask_RCNN/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMcC41nfjCd",
        "colab_type": "code",
        "outputId": "fab676df-fc97-4874-e555-30174f4b3b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: protobuf, termcolor, absl-py, wheel, keras-applications, grpcio, numpy, astor, tensorflow-estimator, gast, tensorboard, keras-preprocessing, six\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0cXN-OOKkVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dR8HxrO_oI7",
        "colab_type": "code",
        "outputId": "7a8852f5-eb00-48ee-b125-35ea28cd791d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "source": [
        "%cd /root/\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "#!git clone --quiet https://github.com/matterport/Mask_RCNN/\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-tk is already the newest version (2.7.15~rc1-1).\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 1,818 kB of archives.\n",
            "After this operation, 7,688 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pil amd64 5.1.0-1 [328 kB]\n",
            "Fetched 1,818 kB in 1s (1,801 kB/s)\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 130912 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "\u001b[K     |████████████████████████████████| 993kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJh-6EXuryi",
        "colab_type": "code",
        "outputId": "8c3fc226-b092-4908-ccb4-51aab13da378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!mkdir -p /content/drive/\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONvvLz1uLM-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98bcab1f-5ecc-4f3b-c1bb-43d02add9457"
      },
      "source": [
        "%cd /root\n",
        "%ls\n",
        "!mv Mask_RCNN/ Mask_RCNN_old/"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "\u001b[0m\u001b[01;34mMask_RCNN_old\u001b[0m/  \u001b[01;34mmodels\u001b[0m/\n",
            "mv: cannot stat 'Mask_RCNN/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz8xh55NKnbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df9e66df-22a7-4b8e-a810-a07cfd92725f"
      },
      "source": [
        "########\n",
        "# Only run this once, not repeatedly\n",
        "########\n",
        "\n",
        "!mkdir -p /content/drive/My\\ Drive/MachineLearning/tools\n",
        "%cd /content/drive/My\\ Drive/MachineLearning/tools/\n",
        "!git clone --quiet https://github.com/matterport/Mask_RCNN/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES-su46RRN_X",
        "colab_type": "code",
        "outputId": "ba5ea5b6-64bb-4767-9460-201c26aee4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "######\n",
        "# Only do this once as the trainied model is stored in this file. -- now stored in google drive\n",
        "######\n",
        "\n",
        "#!mkdir -p /root/data\n",
        "#%cd /content/drive/My\\ Drive/MachineLearning/projects/macbethIdentify_v1\n",
        "#!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\n",
            "--2019-06-08 11:45:50--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-06-08 11:45:50--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190608T114550Z&X-Amz-Expires=300&X-Amz-Signature=e053c00356fd0bdc03a9c9e4b5cf4b32d3681a9ba99b8dd506911e16054a48a7&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.10.11\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.10.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  63.2MB/s    in 4.1s    \n",
            "\n",
            "2019-06-08 11:45:55 (59.2 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSlGKXeL_pzS",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "## This is not needed\n",
        "\n",
        "### Install pycotools\n",
        "##!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRULdCfrA39Y",
        "colab_type": "code",
        "outputId": "4932e0d4-efaf-4f7d-d0ab-9fcfac959790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This is not needed\n",
        "\n",
        "# Compile protocol buffers\n",
        "#%cd ~/models/research\n",
        "#!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khuHLMHuMqAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/drive/My Drive/MachineLearning/tools/Mask_RCNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhhQJov6MM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5de12e10-c5fe-4461-c050-017e71fa3a84"
      },
      "source": [
        "%cd /\n",
        "import six\n",
        "import mrcnn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB5fbc3_piye",
        "colab_type": "code",
        "outputId": "24c9cfd8-eb7d-4e1a-a293-9d27bf1831fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/drive/My\\ Drive/\n",
        "%cd MachineLearning/projects/macbethIdentify_v1/data/img/\n",
        "\n",
        "\n",
        "BASEDIR = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1\"\n",
        "print(os.path.isdir(BASEDIR))\n",
        "\n",
        "\n",
        "WEIGHTS_FILE = \"{0}/{1}\".format(BASEDIR, \"mask_rcnn_coco.h5\")\n",
        "LOG_DIR = \"{0}/{1}\".format(BASEDIR, \"LOGS\")\n",
        "imageFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img\")\n",
        "maskFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/mask_images\")\n",
        "valFilesBasePath = \"{0}/{1}\".format(BASEDIR, \"/data/img_val\")\n",
        "\n",
        "ANNOTATION_DIR = \"{0}/data/annotations\".format(BASEDIR)\n",
        "JSON_DIR = \"{0}/data/annotations_json\".format(BASEDIR)\n",
        "JSON_FILE = \"{0}/via_region_data.json\".format(JSON_DIR)\n",
        "#annotationsFilesBasePath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/data/data/annotations/'\n",
        "#labelMapPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/label_map.pbtxt'\n",
        "#testPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/test.txt'\n",
        "#trainPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/train.txt'\n",
        "#valPath = '/root/data/mine/machineLearning/macbethIdentify/data/macbeth_identify/val.txt'\n",
        "\n",
        "#print(imageFilesBasePath)\n",
        "#print(maskFilesBasePath)\n",
        "#print(valFilesBasePath)\n",
        "print(os.path.isdir(imageFilesBasePath))\n",
        "print(os.path.isdir(maskFilesBasePath))\n",
        "print(os.path.isdir(valFilesBasePath))\n",
        "print(os.path.isfile(WEIGHTS_FILE))\n",
        "print(os.path.isdir(ANNOTATION_DIR))\n",
        "print(os.path.isdir(JSON_DIR))\n",
        "print(os.path.isfile(JSON_FILE))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1/data/img\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHVEpJ6g6bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############\n",
        "# Convert rectlabel annotation to maskrcnn json\n",
        "# This only needs to be run of new images are added to the dataset (and exported from rectlabel)\n",
        "############\n",
        "\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allAnnotations = glob.glob(ANNOTATION_DIR + \"/*\")\n",
        "\n",
        "print(allAnnotations)\n",
        "\n",
        "class JsonAnnotation:\n",
        "    def __init__(self):\n",
        "        self.filename = None\n",
        "        #self.fileref = \"\"\n",
        "        #self.size = \"\"\n",
        "        #self.base64_img_data = \"\"\n",
        "        #self.file_attributes = {}\n",
        "        self.all_points_x = []\n",
        "        self.all_points_y = []\n",
        "        \n",
        "    def dict1(self):\n",
        "        d = {}\n",
        "        d[\"fileref\"] = \"\"\n",
        "        d[\"size\"] = 23232323\n",
        "        d[\"filename\"] = self.filename\n",
        "        d[\"base64_img_data\"] = \"\"\n",
        "        d[\"file_attributes\"] = {}\n",
        "        d[\"regions\"] = self.createRegions()\n",
        "        \n",
        "        return d\n",
        "    \n",
        "    def createRegions(self):\n",
        "        regions = {0 : {}}\n",
        "        regions[0] = {}\n",
        "        regions[0][\"shape_attributes\"] = {}\n",
        "        regions[0][\"shape_attributes\"][\"name\"] = \"polygon\"\n",
        "        regions[0][\"shape_attributes\"][\"region_attributes\"] = {}\n",
        "        regions[0][\"shape_attributes\"][\"all_points_x\"] = self.all_points_x\n",
        "        regions[0][\"shape_attributes\"][\"all_points_y\"] = self.all_points_y\n",
        "        \n",
        "        return regions      \n",
        "    \n",
        "    def getString(self):\n",
        "        return {self.filename: \"test\"}\n",
        "\n",
        "allJsonAnnotations = {}\n",
        "\n",
        "for a in allAnnotations:\n",
        "    #if not a.count(\"megan_rapinoe_mg_0013\"):\n",
        "    #    continue\n",
        "\n",
        "    print(a)\n",
        "    tree = ET.parse(a)\n",
        "    root = tree.getroot()\n",
        "    #print(root)\n",
        "    #print(root.find(\"folder\").text)\n",
        "    #print(root.find(\"object\").get(\"name\"))\n",
        "    #print()\n",
        "\n",
        "    jsonAnnotation = JsonAnnotation()\n",
        "    jsonAnnotation.filename = root.find(\"filename\").text \n",
        "\n",
        "    _object = root.find(\"object\")\n",
        "    name = _object.find(\"name\").text \n",
        " \n",
        "    for child in _object:\n",
        "        if child.tag != \"polygon\":\n",
        "            continue\n",
        "            \n",
        "        for point in child:\n",
        "            #print(point.tag, \": \", point.text)\n",
        "            if point.tag.count(\"x\"):\n",
        "                jsonAnnotation.all_points_x.append(int(point.text))\n",
        "            else:\n",
        "                jsonAnnotation.all_points_y.append(int(point.text))\n",
        "    \n",
        "    allJsonAnnotations[jsonAnnotation.filename] = jsonAnnotation.dict1()\n",
        "    \n",
        "    \n",
        "with open(JSON_FILE, 'w') as f:\n",
        "    result = json.dump(allJsonAnnotations, f)\n",
        "    \n",
        "#print(result)\n",
        "\n",
        "print(\"writing: \", JSON_FILE)\n",
        "#f = open(JSON_FILE, 'w')\n",
        "#f.write(result)\n",
        "\n",
        "    #annotation = root.tag\n",
        "    #\n",
        "    \n",
        "    #polygon = root.find(\"polygon\")\n",
        "\n",
        "    #print(root.find(\"filename\").text)\n",
        "    #print(polygon)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-0tqfOiySx7",
        "colab": {}
      },
      "source": [
        "def getImageFromDir(basePath=None, filename=None, className=None):\n",
        "    name, ext = filename.split(\".\")\n",
        "    dirContents = os.listdir(basePath)\n",
        "    for f in dirContents:\n",
        "        maskName, maskExtension = f.split('.')\n",
        "        #print(\"Has className: \", f, \" \" , className, \" \", className in f)\n",
        "        if f.startswith(name) and className in f:\n",
        "            #print(os.path.join(basePath, f))\n",
        "            return os.path.join(basePath, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0nJZtNoE02X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getExif(image=None, key=None):\n",
        "    \"\"\"\n",
        "    Returns a tuple of exif key and exif value\n",
        "    \"\"\"\n",
        "    for (k, v) in PIL.ExifTags.TAGS.items():\n",
        "        if v.lower() == key:\n",
        "            #print(v.lower(), \" \", key)\n",
        "            if image._getexif():\n",
        "                return (k, image._getexif()[k])\n",
        "            else:\n",
        "                return (k, 1)\n",
        "    \n",
        "def fixOrientation(image=None, orientation=1):\n",
        "\n",
        "    result = image\n",
        "    #print(orientation)\n",
        "    if orientation == 3 : \n",
        "        result =  image.rotate(180, expand=True)\n",
        "    elif orientation == 6 : \n",
        "        result = image.rotate(270, expand=True)\n",
        "    elif orientation == 8 : \n",
        "        result = image.rotate(90, expand=True)\n",
        "        \n",
        "    return result\n",
        "\n",
        "def isValidImage(filename=None):\n",
        "    BLACKLIST = [\"kaztest.jpg\"]\n",
        "    VALID_EXTENSIONS = [\"jpg\", \"png\"]\n",
        "    name, extension = filename.split(\".\")\n",
        "    \n",
        "    if extension.lower() not in VALID_EXTENSIONS:\n",
        "        return False\n",
        "    \n",
        "    if filename in BLACKLIST:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "                        \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBbV9Tora90P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "import numpy as np\n",
        "\n",
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uE2h-mZc3MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class CocoConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 80\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "cocoConfig = CocoConfig()\n",
        "#cocoConfig.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJNOAQTYDgu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coco Inference Config\n",
        "\n",
        "class InferenceCocoConfig(CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "\n",
        "inferenceCocoConfig = InferenceCocoConfig()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25S69brw8Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Run inference on images \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "from PIL import Image\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=inferenceCocoConfig,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = WEIGHTS_FILE\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "    \n",
        "    \n",
        "RESULTS = []\n",
        "\n",
        "for imageFilename in os.listdir(imageFilesBasePath)[20:30]:\n",
        "    if not isValidImage(imageFilename):\n",
        "        continue\n",
        "    \n",
        "    imagePath = os.path.join(imageFilesBasePath, imageFilename)\n",
        "    maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")\n",
        "\n",
        "    if not maskPath:\n",
        "        continue\n",
        "    \n",
        "    _image = skimage.io.imread(imagePath)    \n",
        "    _resizeResult = utils.resize_image(_image, max_dim=1024)\n",
        "    _scale = _resizeResult[2]\n",
        "    _padding = _resizeResult[3]\n",
        "    _crop = _resizeResult[4]\n",
        "    imageSrc = _resizeResult[0]\n",
        "    #imageSrc = utils.resize_image(Image.open(imagePath),max_dim=1024)\n",
        "    _maskSrc = skimage.io.imread(maskPath)  #Image.open(maskPath)\n",
        "    \n",
        "    print(_maskSrc.shape)\n",
        "    print(_image.shape)\n",
        "    \n",
        "    _maskTmp = np.expand_dims(_maskSrc, axis=2)\n",
        "    _maskTmp2 = np.tile(_maskTmp, 3)\n",
        "    #_maskTmp = np.tile(_maskSrc, 3)\n",
        "    print (_maskTmp2.shape)\n",
        "    \n",
        "    print(\"####\")\n",
        "    #print(_image.shape)\n",
        "    #print(_maskSrc.shape)\n",
        "    print(_scale, _padding, _crop)\n",
        "    print(_maskSrc)\n",
        "    maskSrc = utils.resize_mask(_maskTmp2, _scale, _padding, _crop)\n",
        "    print(maskSrc.shape)\n",
        "\n",
        "    #orientation = getExif(imageSrc, \"orientation\")\n",
        "    #imageOrientated = fixOrientation(imageSrc, orientation[1])\n",
        "    image = Image.fromarray(imageSrc)\n",
        "    maskImage = Image.fromarray(maskSrc)\n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = image.split()\n",
        "    channelsMask = maskImage.split()\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], channelsMask[0])\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "        \n",
        "    imageArray = numpy.array(imageSrc)\n",
        "\n",
        "    \n",
        "    #plt.figure(figsize=(8, 6))\n",
        "    #plt.title(imagePath.split(\"/\").pop())\n",
        "    #plt.imshow(newImage)\n",
        "    \n",
        "    result = model.detect([imageArray], verbose=1)[0]\n",
        "    RESULTS.append(result)\n",
        "    splash = color_splash(imageArray, result[\"masks\"])\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(result[\"class_ids\"])\n",
        "    plt.imshow(splash)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U35sKd8mUUnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Macbeth Config\n",
        "\n",
        "from mrcnn.config import Config\n",
        "\n",
        "# Derived from https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
        "class MacbethConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"macbeth\"\n",
        "    \n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    \n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPM_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    \n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    \n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    \n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = MacbethConfig()\n",
        "config.display()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtBuVhcbQckU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def my_resize_image(image, min_dim=None, max_dim=None, min_scale=None, mode=\"square\"):\n",
        "    \"\"\"Resizes an image keeping the aspect ratio unchanged.\n",
        "\n",
        "    min_dim: if provided, resizes the image such that it's smaller\n",
        "        dimension == min_dim\n",
        "    max_dim: if provided, ensures that the image longest side doesn't\n",
        "        exceed this value.\n",
        "    min_scale: if provided, ensure that the image is scaled up by at least\n",
        "        this percent even if min_dim doesn't require it.\n",
        "    mode: Resizing mode.\n",
        "        none: No resizing. Return the image unchanged.\n",
        "        square: Resize and pad with zeros to get a square image\n",
        "            of size [max_dim, max_dim].\n",
        "        pad64: Pads width and height with zeros to make them multiples of 64.\n",
        "               If min_dim or min_scale are provided, it scales the image up\n",
        "               before padding. max_dim is ignored in this mode.\n",
        "               The multiple of 64 is needed to ensure smooth scaling of feature\n",
        "               maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
        "        crop: Picks random crops from the image. First, scales the image based\n",
        "              on min_dim and min_scale, then picks a random crop of\n",
        "              size min_dim x min_dim. Can be used in training only.\n",
        "              max_dim is not used in this mode.\n",
        "\n",
        "    Returns:\n",
        "    image: the resized image\n",
        "    window: (y1, x1, y2, x2). If max_dim is provided, padding might\n",
        "        be inserted in the returned image. If so, this window is the\n",
        "        coordinates of the image part of the full image (excluding\n",
        "        the padding). The x2, y2 pixels are not included.\n",
        "    scale: The scale factor used to resize the image\n",
        "    padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]\n",
        "    \"\"\"\n",
        "    # Keep track of image dtype and return results in the same dtype\n",
        "    image_dtype = image.dtype\n",
        "    # Default window (y1, x1, y2, x2) and default scale == 1.\n",
        "    h, w = image.shape[:2]\n",
        "    window = (0, 0, h, w)\n",
        "    scale = 1\n",
        "    padding = [(0, 0), (0, 0), (0, 0)]\n",
        "    crop = None\n",
        "\n",
        "    if mode == \"none\":\n",
        "        return image, window, scale, padding, crop\n",
        "\n",
        "    # Scale?\n",
        "    if min_dim:\n",
        "        # Scale up but not down\n",
        "        scale = max(1, min_dim / min(h, w))\n",
        "    if min_scale and scale < min_scale:\n",
        "        scale = min_scale\n",
        "\n",
        "    # Does it exceed max dim?\n",
        "    if max_dim and mode == \"square\":\n",
        "        image_max = max(h, w)\n",
        "        if round(image_max * scale) > max_dim:\n",
        "            scale = max_dim / image_max\n",
        "\n",
        "    # Resize image using bilinear interpolation\n",
        "    if scale != 1:\n",
        "        image = utils.resize(image, (round(h * scale), round(w * scale)),\n",
        "                       preserve_range=True)\n",
        "\n",
        "    # Need padding or cropping?\n",
        "    if mode == \"square\":\n",
        "        # Get new height and width\n",
        "        h, w = image.shape[:2]\n",
        "        top_pad = (max_dim - h) // 2\n",
        "        bottom_pad = max_dim - h - top_pad\n",
        "        left_pad = (max_dim - w) // 2\n",
        "        right_pad = max_dim - w - left_pad\n",
        "        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "        window = (top_pad, left_pad, h + top_pad, w + left_pad)\n",
        "    elif mode == \"pad64\":\n",
        "        h, w = image.shape[:2]\n",
        "        # Both sides must be divisible by 64\n",
        "        assert min_dim % 64 == 0, \"Minimum dimension must be a multiple of 64\"\n",
        "        # Height\n",
        "        if h % 64 > 0:\n",
        "            max_h = h - (h % 64) + 64\n",
        "            top_pad = (max_h - h) // 2\n",
        "            bottom_pad = max_h - h - top_pad\n",
        "        else:\n",
        "            top_pad = bottom_pad = 0\n",
        "        # Width\n",
        "        if w % 64 > 0:\n",
        "            max_w = w - (w % 64) + 64\n",
        "            left_pad = (max_w - w) // 2\n",
        "            right_pad = max_w - w - left_pad\n",
        "        else:\n",
        "            left_pad = right_pad = 0\n",
        "        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\n",
        "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
        "        window = (top_pad, left_pad, h + top_pad, w + left_pad)\n",
        "    elif mode == \"crop\":\n",
        "        # Pick a random crop\n",
        "        h, w = image.shape[:2]\n",
        "        y = random.randint(0, (h - min_dim))\n",
        "        x = random.randint(0, (w - min_dim))\n",
        "        crop = (y, x, min_dim, min_dim)\n",
        "        image = image[y:y + min_dim, x:x + min_dim]\n",
        "        window = (0, 0, min_dim, min_dim)\n",
        "    else:\n",
        "        raise Exception(\"Mode {} not supported\".format(mode))\n",
        "    return image.astype(image_dtype), window, scale, padding, crop\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCSAPTkbX5mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(BASEDIR)\n",
        "\n",
        "# URL from which to download the latest COCO trained weights\n",
        "COCO_MODEL_URL = \"https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = \"/root/LOGS/\"\n",
        "\n",
        "#imageFilesBasePath = \"/root/data/mine/machineLearning/macbethIdentify/data/data/img\"\n",
        "maskFilesBasePath = maskFilesBasePath\n",
        "\n",
        "\n",
        "# Dataset\n",
        "class MacbethDataset(utils.Dataset):\n",
        "    #def __init__(self):\n",
        "    #    super().__init__()\n",
        "    #    self.imageResizeParams = {}\n",
        "    \n",
        "    def load_macbeths(self, dataset_dir, subset):\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"macbeth\", 1, \"macbeth\")\n",
        "        \n",
        "        i = 0\n",
        "\n",
        "        _annotationsFile = json.load(open(JSON_FILE))\n",
        "        annotations = [x for x in list(_annotationsFile.values()) if x['regions'] ]\n",
        "        \n",
        "        for a in annotations:\n",
        "            \n",
        "            polygons = []\n",
        "            for region in a['regions'].values():\n",
        "                #print(region) #[\"shape_attributes\"]\n",
        "                #print(region['shape_attributes'])\n",
        "                polygons.append(region['shape_attributes'])             \n",
        "\n",
        "            #print(polygons)\n",
        "            \n",
        "            imagePath = os.path.join(imageFilesBasePath, a[\"filename\"])\n",
        "\n",
        "            if not os.path.isfile(imagePath):\n",
        "                continue\n",
        "                \n",
        "            _image = skimage.io.imread(imagePath)\n",
        "            height, width = _image.shape[:2]\n",
        "                \n",
        "            #print(os.path.isfile(imagePath))            \n",
        "            #print(height, width)\n",
        "            \n",
        "            self.add_image(\n",
        "                \"macbeth\",\n",
        "                image_id=a[\"filename\"],\n",
        "                path=imagePath,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                polygons=polygons\n",
        "            )\n",
        "            #self._image_ids.append(i)\n",
        "            #i += 1\n",
        "            \n",
        "        \"\"\"    \n",
        "        for imageFilename in os.listdir(dataset_dir)[:0]:\n",
        "            if not isValidImage(imageFilename):\n",
        "                continue\n",
        "    \n",
        "            imagePath = os.path.join(dataset_dir, imageFilename)\n",
        "            maskPath = getImageFromDir(maskFilesBasePath, imageFilename, \"macbeth\")  \n",
        "            \n",
        "            if not maskPath:\n",
        "                continue\n",
        "                \n",
        "            if not os.path.isfile(imagePath):\n",
        "                continue\n",
        "                \n",
        "            if not os.path.isfile(maskPath):\n",
        "                continue\n",
        "                \n",
        "\n",
        "            \n",
        "            _image = skimage.io.imread(imagePath)\n",
        "            #print(_image.shape)\n",
        "            _resizeResults = my_resize_image(_image, max_dim=1024)\n",
        "            #print(\"_resizeResults: \", _resizeResults)\n",
        "            image = _resizeResults[0]\n",
        "            _scale = _resizeResults[2]\n",
        "            _padding = _resizeResults[3]\n",
        "            _crop = _resizeResults[4]\n",
        "\n",
        "            #print(\"_scale: \", _scale, \"_padding: \", _padding)\n",
        "            self.imageResizeParams[i] = [_scale, _padding, _crop]\n",
        "            height, width = image.shape[:2]\n",
        "            #print(width, height)\n",
        "            #print(\"Adding: \", imagePath)\n",
        "            #print(\"Adding: \", maskPath)\n",
        "            self.add_image(\n",
        "                \"macbeth\",\n",
        "                image_id=i,\n",
        "                path=imagePath,\n",
        "                width=width,\n",
        "                height=height\n",
        "            )\n",
        "            self._image_ids.append(i)\n",
        "            i += 1\n",
        "            \"\"\"\n",
        "        \n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        #print(\"load image\")\n",
        "        #print(type(self.image_info))\n",
        "        ##print(self.image_info[image_id])\n",
        "        #print(self.image_info[image_id]['path'])\n",
        "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "            \n",
        "        return image\n",
        "    \n",
        "    \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        \n",
        "        print(\"load_mask\")\n",
        "        \n",
        "        # If not a balloon dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        #print(image_info)\n",
        "        if image_info[\"source\"] != \"macbeth\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "\n",
        "        print(info[\"height\"], \" - \", info[\"width\"], \" : \", len(info[\"polygons\"]))\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        \n",
        "        print(\"x: \", info['polygons'][0][\"all_points_x\"])\n",
        "        print(\"y: \", info['polygons'][0][\"all_points_y\"])\n",
        "        \n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            #print(p['all_points_y'])\n",
        "            #print(p['all_points_x'])\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            print(i, \": \", rr, \"-\", cc)\n",
        "            mask[rr, cc] = 1\n",
        "\n",
        "    \n",
        "        #print(mask.shape)\n",
        "        return mask\n",
        "        print(\"TEST\")\n",
        "        print(mask.shape[-1])\n",
        "        print(mask.shape)\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)    \n",
        "        \n",
        "    \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"macbeth\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1K36Et6c6BI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "a5884db8-7e76-4676-c0e9-d7901b3a5435"
      },
      "source": [
        "#\n",
        "# Visualise image and matte overlays are working through the dataset class\n",
        "#\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "\n",
        "for i in range(len(dataset_train.image_info))[:5]:\n",
        "\n",
        "    _img = dataset_train.load_image(i)\n",
        "    _mask = dataset_train.load_mask(i)\n",
        "    \n",
        "    #mask = np.zeros([1022, 766, 1], dtype=np.uint8)\n",
        "    \n",
        "    #print(mask.shape)\n",
        "    \n",
        "    mask = _mask[:, :, 0].copy()\n",
        "    \n",
        "    #print(t.shape)\n",
        "    \n",
        "    \n",
        "    #r = np.array([335, 405, 398, 331])\n",
        "    #c = np.array([519, 518, 419, 422])\n",
        "    \n",
        "    #rr, cc = skimage.draw.polygon(r, c)\n",
        "    #t[rr, cc] = 1\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(mask)\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    continue\n",
        "    print(_img.shape)\n",
        "    print(_mask.shape)\n",
        "    # Test overlays of masks\n",
        "    channels = _img.split()\n",
        "    #print(channels)\n",
        "    #print(mask)\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], _mask)\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "        \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(newImage)\n",
        "    \"\"\"\n",
        "    \n",
        "   \n",
        "    \"\"\"\n",
        "    continue\n",
        "    #_resizeResults = my_resize_image(_img, max_dim=1024)\n",
        "    img = Image.fromarray(_resizeResults[0])\n",
        "    \n",
        "    \n",
        "    #tst = dataset_train.load_image(f)\n",
        "    #print(tst.dtype)\n",
        "    #img2 = utils.resize_image(img, max_dim=1024)\n",
        "    \n",
        "    mask = Image.fromarray(dataset_train.load_mask(f)[1])\n",
        "    \n",
        "    #print(\"img.size: \", img.size)\n",
        "    #print(\"width: \", mask.width)\n",
        "    #print(\"height:\", mask.height)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    #plt.title(\"banana\")\n",
        "    plt.imshow(mask)\n",
        "    \n",
        "    \n",
        "    # Test overlays of masks\n",
        "    channels = img.split()\n",
        "    #print(channels)\n",
        "    #print(mask)\n",
        "    \n",
        "    testImage = PIL.ImageChops.add(channels[0], mask)\n",
        "    newImage = Image.merge(\"RGB\", (testImage, channels[1], channels[2]))\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(\"banana\")\n",
        "    plt.imshow(newImage)\n",
        "\"\"\"    \n",
        "    \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load_mask\n",
            "1022  -  766  :  1\n",
            "x:  [335, 405, 398, 331]\n",
            "y:  [519, 518, 419, 422]\n",
            "0 :  [420 420 420 ... 518 518 518] - [376 377 378 ... 402 403 404]\n",
            "(1022, 766, 1)\n",
            "load_mask\n",
            "1869  -  1400  :  1\n",
            "x:  [369, 608, 608, 608, 369]\n",
            "y:  [769, 769, 685, 601, 601]\n",
            "0 :  [601 601 601 ... 768 768 768] - [369 370 371 ... 605 606 607]\n",
            "(1869, 1400, 1)\n",
            "load_mask\n",
            "961  -  720  :  1\n",
            "x:  [301, 391, 448, 358]\n",
            "y:  [362, 444, 382, 300]\n",
            "0 :  [301 301 302 ... 442 443 443] - [358 359 357 ... 392 390 391]\n",
            "(961, 720, 1)\n",
            "load_mask\n",
            "1153  -  864  :  1\n",
            "x:  [216, 366, 358, 208]\n",
            "y:  [593, 581, 478, 490]\n",
            "0 :  [479 479 479 ... 592 592 592] - [346 347 348 ... 226 227 228]\n",
            "(1153, 864, 1)\n",
            "load_mask\n",
            "1295  -  864  :  1\n",
            "x:  [253, 490, 493, 492, 243]\n",
            "y:  [804, 799, 735, 668, 674]\n",
            "0 :  [669 669 669 ... 803 803 803] - [451 452 453 ... 298 299 300]\n",
            "(1295, 864, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAJCCAYAAACroDz3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDZEEgIZIAkBDJAGgIZIA0BBJAGj8fxwVSzKJvh0XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAJCCAYAAAB07kboAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB5AQPUhvMsaJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAJCCAYAAAC8gqw+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWhPDAFo7/8Dt12RBOuGZEsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAJCCAYAAACroDz3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQCN/w/pvzd5sLv49gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAJCCAYAAAD0nXH7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF5ZJREFUeJzt3X+s5XV95/HXe2dgEC0Mg4bQGVIw\nJTZs01V2IhgbY5xWgRrxD9dgmpW6bCa7a3e1bmJhm6zp7j91t6nVpGuXFFvcuKildiHGLiLaNLuJ\nKCgiP1Ru/cXMgvgDsKm7Cu1n/zifwevwY+Dey/ueyzweyc39fj/ne+55D/fMPOf7PWcuNcYIADzd\n/sFmDwDA0UFwAGghOAC0EBwAWggOAC0EB4AW7cGpqvOq6stVtVJVl3Y/PgCbozr/HU5VbUvylSS/\nnORAks8mecMY4462IQDYFN1nOC9OsjLG+OoY40dJPpjkwuYZANgE25sfb3eSu1ftH0hyzuoDqmp/\nkv1Jsi3b/vHxOaFvOgCesr/J/d8ZYzzvSMd1B+eIxhiXJ7k8SU6oXeOc2rfJEwHwRD4xrv7Gkzmu\n+5LawSSnrdrfM9cAeIbrDs5nk5xZVWdU1bFJLkpybfMMAGyC1ktqY4yHq+rXk1yXZFuS940xbu+c\nAYDN0f4azhjjY0k+1v24AGwuP2kAgBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNA\nC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQH\ngBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoI\nDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0\nEBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAA\naCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgxZqDU1WnVdWnquqOqrq9qt4y13dV1fVVddf8fNJcr6p6\nT1WtVNWtVXX2Rv0iAFh+6znDeTjJvx1jnJXk3CRvrqqzklya5IYxxplJbpj7SXJ+kjPnx/4k713H\nYwOwxaw5OGOMe8YYn5vbf5PkziS7k1yY5Mp52JVJXju3L0zy/rHw6SQ7q+rUNU8OwJayIa/hVNXp\nSV6U5MYkp4wx7pk33ZvklLm9O8ndq+52YK4d/rX2V9VNVXXTQ/nhRowHwBJYd3Cq6jlJ/izJW8cY\n31992xhjJBlP5euNMS4fY+wdY+w9JjvWOx4AS2JdwamqY7KIzQfGGB+Zy986dKlsfr5vrh9Mctqq\nu++ZawAcBdbzLrVKckWSO8cYv7fqpmuTXDy3L05yzar1N853q52b5MFVl94AeIbbvo77vjTJP03y\nxaq6Za79uyS/k+TDVXVJkm8kef287WNJLkiykuQHSd60jscGYItZc3DGGP8rST3Ozfse4/iR5M1r\nfTwAtjY/aQCAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGgh\nOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQ\nQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EB\noIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaC\nA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAt\nBAeAFoIDQAvBAaDFuoNTVduq6vNV9dG5f0ZV3VhVK1X1oao6dq7vmPsr8/bT1/vYAGwdG3GG85Yk\nd67af2eSd40xfjbJ/UkumeuXJLl/rr9rHgfAUWJdwamqPUl+Jckfzf1K8ookV89Drkzy2rl94dzP\nvH3fPB6Ao8B6z3B+P8nbk/z93D85yQNjjIfn/oEku+f27iR3J8m8/cF5/E+oqv1VdVNV3fRQfrjO\n8QBYFmsOTlW9Osl9Y4ybN3CejDEuH2PsHWPsPSY7NvJLA7CJtq/jvi9N8pqquiDJcUlOSPLuJDur\navs8i9mT5OA8/mCS05IcqKrtSU5M8t11PD4AW8iaz3DGGJeNMfaMMU5PclGST44xfjXJp5K8bh52\ncZJr5va1cz/z9k+OMcZaHx+AreXp+Hc4v5nkbVW1ksVrNFfM9SuSnDzX35bk0qfhsQFYUuu5pPaI\nMcZfJvnLuf3VJC9+jGP+X5J/shGPB8DW4ycNANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF\n4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNA\nC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQH\ngBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoI\nDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0\nEBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtFhXcKpqZ1VdXVVfqqo7q+olVbWrqq6vqrvm\n55PmsVVV76mqlaq6tarO3phfAgBbwXrPcN6d5H+OMX4uyT9KcmeSS5PcMMY4M8kNcz9Jzk9y5vzY\nn+S963xsALaQNQenqk5M8rIkVyTJGONHY4wHklyY5Mp52JVJXju3L0zy/rHw6SQ7q+rUNU8OwJay\nnjOcM5J8O8kfV9Xnq+qPqurZSU4ZY9wzj7k3ySlze3eSu1fd/8Bc+wlVtb+qbqqqmx7KD9cxHgDL\nZD3B2Z7k7CTvHWO8KMnf5seXz5IkY4yRZDyVLzrGuHyMsXeMsfeY7FjHeAAsk/UE50CSA2OMG+f+\n1VkE6FuHLpXNz/fN2w8mOW3V/ffMNQCOAmsOzhjj3iR3V9UL5tK+JHckuTbJxXPt4iTXzO1rk7xx\nvlvt3CQPrrr0BsAz3PZ13v9fJ/lAVR2b5KtJ3pRFxD5cVZck+UaS189jP5bkgiQrSX4wjwXgKLGu\n4Iwxbkmy9zFu2vcYx44kb17P4wGwdflJAwC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgA\ntBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0GL7\nZg8AzxTX/Z9bNnuER7zqp1+42SPAowgOW9oy/SEPPDHB4SnzhzywFl7D4SlzuQZYC8EBoIXgANBC\ncABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCw5r4f+IA\nT5XgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4rJkfbwM8FYIDQAvBAaCF\n4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0Eh3Xx/8RZ\nPr4nLCvBAaCF4ADQQnAAaCE4ALQQHABarCs4VfUbVXV7Vd1WVVdV1XFVdUZV3VhVK1X1oao6dh67\nY+6vzNtP34hfAABbw5qDU1W7k/ybJHvHGD+fZFuSi5K8M8m7xhg/m+T+JJfMu1yS5P65/q55HABH\nifVeUtue5FlVtT3J8UnuSfKKJFfP269M8tq5feHcz7x9X1XVOh8fgC1i+1rvOMY4WFW/m+SbSf5v\nko8nuTnJA2OMh+dhB5Lsntu7k9w97/twVT2Y5OQk31n9datqf5L9SXJcjl/rePC08Q8rYW3WHJyq\nOimLs5YzkjyQ5E+TnLfegcYYlye5PElOqF1jvV+Prccf6PDMtObgJPmlJF8bY3w7SarqI0lemmRn\nVW2fZzl7khycxx9MclqSA/MS3IlJvruOx2dJCATwZKznNZxvJjm3qo6fr8XsS3JHkk8led085uIk\n18zta+d+5u2fHGM4gwE4Sqw5OGOMG7N48f9zSb44v9blSX4zyduqaiWL12iumHe5IsnJc/1tSS5d\nx9wAbDG1zCcZJ9SucU7t2+wxAHgCnxhX3zzG2Huk4/ykAQBaCA4ALQQHgBaCA0ALwQGgheAA0EJw\nAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF\n4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNA\nC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQH\ngBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoI\nDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBZHDE5Vva+q7quq21at7aqq66vq\nrvn5pLleVfWeqlqpqlur6uxV97l4Hn9XVV389PxyAFhWT+YM50+SnHfY2qVJbhhjnJnkhrmfJOcn\nOXN+7E/y3mQRqCTvSHJOkhcnecehSAFwdDhicMYYf5Xke4ctX5jkyrl9ZZLXrlp//1j4dJKdVXVq\nklcluX6M8b0xxv1Jrs+jIwbAM9j2Nd7vlDHGPXP73iSnzO3dSe5eddyBufZ4649SVfuzODvKcTl+\njeMBsGzW/aaBMcZIMjZglkNf7/Ixxt4xxt5jsmOjviwAm2ytwfnWvFSW+fm+uX4wyWmrjtsz1x5v\nHYCjxFqDc22SQ+80uzjJNavW3zjfrXZukgfnpbfrkryyqk6abxZ45VwD4ChxxNdwquqqJC9P8tyq\nOpDFu81+J8mHq+qSJN9I8vp5+MeSXJBkJckPkrwpScYY36uq/5jks/O4/zDGOPyNCAA8g9XiJZjl\ndELtGufUvs0eA4An8Ilx9c1jjL1HOs5PGgCgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EB\noIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaC\nA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAt\nBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGghOAC0EBwA\nWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4\nALQQHABaCA4ALQQHgBaCA0ALwQGgheAA0EJwAGhxxOBU1fuq6r6qum3V2n+uqi9V1a1V9edVtXPV\nbZdV1UpVfbmqXrVq/by5tlJVl278LwWAZfZkznD+JMl5h61dn+Tnxxi/kOQrSS5Lkqo6K8lFSf7h\nvM9/qaptVbUtyR8kOT/JWUneMI8F4ChxxOCMMf4qyfcOW/v4GOPhufvpJHvm9oVJPjjG+OEY42tJ\nVpK8eH6sjDG+Osb4UZIPzmMBOEpsxGs4/yzJX8zt3UnuXnXbgbn2eOuPUlX7q+qmqrrpofxwA8YD\nYBmsKzhV9VtJHk7ygY0ZJxljXD7G2DvG2HtMdmzUlwVgk21f6x2r6teSvDrJvjHGmMsHk5y26rA9\ncy1PsA7AUWBNZzhVdV6Styd5zRjjB6tuujbJRVW1o6rOSHJmks8k+WySM6vqjKo6Nos3Fly7vtEB\n2EqOeIZTVVcleXmS51bVgSTvyOJdaTuSXF9VSfLpMca/GGPcXlUfTnJHFpfa3jzG+Lv5dX49yXVJ\ntiV53xjj9qfh1wPAkqofXw1bPifUrnFO7dvsMQB4Ap8YV988xth7pOP8pAEAWggOAC0EB4AWggNA\nC8EBoIXgANBCcABoITgAtBAcAFoIDgAtBAeAFoIDQAvBAaCF4ADQQnAAaCE4ALQQHABaCA4ALQQH\ngBaCA0ALwQGgheAA0EJwAGghOAC0EBwAWggOAC0EB4AWggNAC8EBoIXgANBCcABoITgAtBAcAFoI\nDgAtaoyx2TM8rqr6dpK/TfKdzZ7lSXhuzLmRzLmxzLlxtsKMSe+cPzPGeN6RDlrq4CRJVd00xti7\n2XMciTk3ljk3ljk3zlaYMVnOOV1SA6CF4ADQYisE5/LNHuBJMufGMufGMufG2QozJks459K/hgPA\nM8NWOMMB4BlAcABosbTBqarzqurLVbVSVZdu8izvq6r7quq2VWu7qur6qrprfj5prldVvWfOfWtV\nnd0452lV9amquqOqbq+qtyzjrFV1XFV9pqq+MOf87bl+RlXdOOf5UFUdO9d3zP2VefvpHXOumndb\nVX2+qj66rHNW1der6otVdUtV3TTXlur7Ph97Z1VdXVVfqqo7q+olyzZnVb1g/nc89PH9qnrrss05\nH/s35u+h26rqqvl7a+men48YYyzdR5JtSf46yfOTHJvkC0nO2sR5Xpbk7CS3rVr7T0kunduXJnnn\n3L4gyV8kqSTnJrmxcc5Tk5w9t38qyVeSnLVss87He87cPibJjfPxP5zkorn+h0n+5dz+V0n+cG5f\nlORDzd//tyX570k+OveXbs4kX0/y3MPWlur7Ph/7yiT/fG4fm2TnMs65at5tSe5N8jPLNmeS3Um+\nluRZq56Xv7aMz89HZu5+wCf5H/IlSa5btX9Zkss2eabT85PB+XKSU+f2qUm+PLf/a5I3PNZxmzDz\nNUl+eZlnTXJ8ks8lOSeLfxW9/fDnQJLrkrxkbm+fx1XTfHuS3JDkFUk+Ov9QWcY5v55HB2epvu9J\nTpx/QNYyz3nYbK9M8r+Xcc4sgnN3kl3z+fbRJK9axufnoY9lvaR26D/kIQfm2jI5ZYxxz9y+N8kp\nc3spZp+nyy/K4uxh6Wadl6luSXJfkuuzOKN9YIzx8GPM8sic8/YHk5zcMWeS30/y9iR/P/dPXtI5\nR5KPV9XNVbV/ri3b9/2MJN9O8sfzEuUfVdWzl3DO1S5KctXcXqo5xxgHk/xukm8muSeL59vNWc7n\nZ5Ilfg1nKxmLvzIszfvLq+o5Sf4syVvHGN9ffduyzDrG+LsxxguzOIN4cZKf2+SRHqWqXp3kvjHG\nzZs9y5Pwi2OMs5Ocn+TNVfWy1Tcuyfd9exaXpt87xnhRFj8n8Sden12SOZMk87WP1yT508NvW4Y5\n52tIF2YR8p9O8uwk523mTEeyrME5mOS0Vft75toy+VZVnZok8/N9c31TZ6+qY7KIzQfGGB9Z5lmT\nZIzxQJJPZXHqv7Oqtj/GLI/MOW8/Mcl3G8Z7aZLXVNXXk3wwi8tq717COQ/9bTdjjPuS/HkWEV+2\n7/uBJAfGGDfO/auzCNCyzXnI+Uk+N8b41txftjl/KcnXxhjfHmM8lOQjWTxnl+75eciyBuezSc6c\n77Y4NovT2ms3eabDXZvk4rl9cRavlxxaf+N858q5SR5cdRr+tKqqSnJFkjvHGL+3rLNW1fOqaufc\nflYWrzPdmUV4Xvc4cx6a/3VJPjn/hvm0GmNcNsbYM8Y4PYvn4CfHGL+6bHNW1bOr6qcObWfxusNt\nWbLv+xjj3iR3V9UL5tK+JHcs25yrvCE/vpx2aJ5lmvObSc6tquPn7/1D/z2X6vn5EzpfMHqKL4hd\nkMW7rP46yW9t8ixXZXGN9KEs/pZ2SRbXPm9IcleSTyTZNY+tJH8w5/5ikr2Nc/5iFqf5tya5ZX5c\nsGyzJvmFJJ+fc96W5N/P9ecn+UySlSwuY+yY68fN/ZV5+/M34Tnw8vz4XWpLNeec5wvz4/ZDv1+W\n7fs+H/uFSW6a3/v/keSkJZ3z2Vn87f/EVWvLOOdvJ/nS/H3035LsWLbn5+oPP9oGgBbLekkNgGcY\nwQGgheAA0EJwAGghOAC0EBwAWggOAC3+P3wzBtEuC3FKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPQcbYWaPUl",
        "colab_type": "code",
        "outputId": "d40353ac-fe20-4333-f5d2-e4fe5e652f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# test stuff\n",
        "imgPath = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/img/penn_jillette_00135.jpg\"\n",
        "maskPath = \"/content/drive/My Drive/MachineLearning/projects/macbethIdentify_v1//data/mask_images/penn_jillette_00135_class_macbeth.png\"\n",
        "#mask = np.zeros([1000, 2000, 1], dtype=np.uint8)\n",
        "\n",
        "#test = MacbethDataset()\n",
        "#test.load_macbeths(imageFilesBasePath, \"train\")\n",
        "\n",
        "#array = test.load_image(1)\n",
        "\n",
        "#print(type(array))\n",
        "#print(type(mask))\n",
        "\n",
        "#print(array.shape)\n",
        "\n",
        "image = skimage.io.imread(imgPath)\n",
        "_mask = skimage.io.imread(maskPath)\n",
        "\n",
        "mask = numpy.expand_dims(_mask, axis=2)\n",
        "\n",
        "print(image.shape)\n",
        "print(_mask.shape)\n",
        "print(mask.shape)\n",
        "\n",
        "resized_image = utils.resize_image(image, max_dim=1024)\n",
        "resized_mask = utils.resize_mask(mask, resized_image[2], resized_image[3])\n",
        "\n",
        "print(resized_image[0].shape)\n",
        "print(resized_mask.shape)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1869, 1400, 3)\n",
            "(1869, 1400)\n",
            "(1869, 1400, 1)\n",
            "(1024, 1024, 3)\n",
            "(1024, 1024, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX9GlLlfikA",
        "colab_type": "code",
        "outputId": "bf5db0a0-dd99-492d-c329-a09157d98810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "#\n",
        "# Perform Training\n",
        "#\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "print(\"FSFDFDF\")\n",
        "\n",
        "dataset_train = MacbethDataset()\n",
        "dataset_train.load_macbeths(imageFilesBasePath, \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "#dataset_val = MacbethDataset()\n",
        "#dataset_val.load_macbeths(\"/root/data/mine/machineLearning/macbethIdentify/data/data/img_val\", \"val\")\n",
        "#dataset_val.prepare()\n",
        "\n",
        "print(\"Training network heads\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "           learning_rate=config.LEARNING_RATE,\n",
        "           epochs=30,\n",
        "           layers='heads')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ab96180e5a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_LOGS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FSFDFDF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacbethDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2463\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2464\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2465\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \"\"\"\n\u001b[1;32m   1761\u001b[0m     assign = state_ops.assign(self._variable, value, use_locking=use_locking,\n\u001b[0;32m-> 1762\u001b[0;31m                               name=name)\n\u001b[0m\u001b[1;32m   1763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    221\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    222\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 8 and 324. Shapes are [1024,8] and [1024,324]. for 'Assign_2738' (op: 'Assign') with input shapes: [1024,8], [1024,324]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMIy8eWoiJLN",
        "colab_type": "code",
        "outputId": "ea28761c-0dcb-4ee2-c99c-ebb939ec9489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%cd ~/data//mine/machineLearning/macbethIdentify/data/data/\n",
        "%ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/data/mine/machineLearning/macbethIdentify/data/data\n",
            "total 48\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mannottions_json\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 05:05 \u001b[01;34mimg\u001b[0m/\n",
            "drwx------ 2 root root  4096 May 26 04:59 \u001b[01;34mimg_val\u001b[0m/\n",
            "-rwx------ 1 root root    34 Apr 27 03:50 \u001b[01;32mlabel_map.pbtxt\u001b[0m*\n",
            "drwx------ 2 root root 16384 May 26 05:05 \u001b[01;34mmask_images\u001b[0m/\n",
            "-rwx------ 1 root root   127 Apr  9 00:21 \u001b[01;32mtest.txt\u001b[0m*\n",
            "-rwx------ 1 root root  1031 Apr 27 03:50 \u001b[01;32mtrain.txt\u001b[0m*\n",
            "-rwx------ 1 root root   141 Apr  9 00:21 \u001b[01;32mval.txt\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd4KUgaZMLl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}